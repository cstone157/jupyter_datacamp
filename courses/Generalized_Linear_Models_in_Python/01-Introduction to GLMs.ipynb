{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc34d9bd-4316-43ec-9c30-f187b6653753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from statsmodels.formula.api import ols, glm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "salary = pd.read_csv('../../data/salary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4279945-87f7-4628-8ecb-ca8f6be6bed1",
   "metadata": {},
   "source": [
    "## Linear model, a special case of GLM\n",
    "### In this exercise you will fit a linear model two ways, one using the ols() function and one using the glm() function. This will show how a linear model is a special case of a generalized linear model (GLM).\n",
    "\n",
    "### You will use the preloaded salary dataset introduced in the video.\n",
    "### Recall that the linear model in Python is defined as: ols(formula = 'y ~ X', data = my_data).fit()\n",
    "### and the generalized linear model can be trained using [FORMULAS EXCLUDED] glm(formula = 'y ~ X', data = my_data, family = sm.families.___).fit()\n",
    "\n",
    "### Instructions \n",
    "-    Import the statsmodels.api with the common alias sm, and the ols and glm modules from the statsmodels.formula.api.\n",
    "-    Fit a linear model by predicting Salary with Experience using the salary dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287af1e2-0a64-4134-b64e-52e0f4ccee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols, glm\n",
    "\n",
    "# Fit a linear model\n",
    "model_lm = ols(formula = 'Salary ~ Experience',\n",
    "               data = salary).fit()\n",
    "\n",
    "# View model coefficients\n",
    "print(model_lm.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a6bd9d-b0de-4225-86ea-6cb61cd06ce3",
   "metadata": {},
   "source": [
    "-    Fit a GLM using the same formula and data, as for the linear model, but this time include the Gaussian() family as additional input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0632b0d-1ec6-46a5-b220-1c5bbbd58e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols, glm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Fit a GLM\n",
    "model_glm = glm(formula = 'Salary ~ Experience',\n",
    "                data = salary,\n",
    "                family = sm.families.Gaussian()).fit()\n",
    "\n",
    "# View model coefficients\n",
    "print(model_glm.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0446c457-184f-430c-8bf5-80de0415fd35",
   "metadata": {},
   "source": [
    "## Linear model and a binary response variable\n",
    "### In the video, you saw an example of fitting a linear model to a binary response variable and how things can go wrong quickly. You learned that, given the linear line fit, you can obtain fitted values , which are not in line with the logic of the problem since the response variable takes on values 0 and 1.\n",
    "\n",
    "### Using the preloaded crab dataset, you will study this effect by modeling y as a function of x using the GLM framework.\n",
    "\n",
    "### Recall that the GLM model formulation is:\n",
    "### glm(formula = 'y ~ X', data = my_data, family = sm.families.____).fit() <missing formulat> where you specify formula, data, and family.\n",
    "\n",
    "### Also, recall that a GLM with:\n",
    "\n",
    "-    the Gaussian family is a linear model (a special case of GLMs)\n",
    "-    the Binomial family is a logistic regression model.\n",
    "\n",
    "### Instruction\n",
    "-    Using the crab dataset, define the model formula so that y is predicted by width.\n",
    "-    To fit a linear model using GLM formula, use Gaussian() for the family argument which assumes y is continuous and approximately normally distributed.\n",
    "-    To fit a logistic model using GLM formula, use Binomial() for the family argument.\n",
    "-    Fit a model using glm() with appropriate arguments and use print() and summary() to view summaries of the fitted models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b933b05-895d-4d4a-b28e-f1059001c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crab = pd.read_csv(\"data/crab.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89990515-b3ac-473c-b9b5-efd6aa29af0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  173\n",
      "Model:                            GLM   Df Residuals:                      171\n",
      "Model Family:                Gaussian   Df Model:                            1\n",
      "Link Function:               Identity   Scale:                         0.19515\n",
      "Method:                          IRLS   Log-Likelihood:                -103.13\n",
      "Date:                Tue, 12 Mar 2024   Deviance:                       33.371\n",
      "Time:                        04:04:04   Pearson chi2:                     33.4\n",
      "No. Iterations:                     3   Pseudo R-squ. (CS):             0.1730\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -1.7655      0.421     -4.190      0.000      -2.591      -0.940\n",
      "width          0.0915      0.016      5.731      0.000       0.060       0.123\n",
      "==============================================================================\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  173\n",
      "Model:                            GLM   Df Residuals:                      171\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -97.226\n",
      "Date:                Tue, 12 Mar 2024   Deviance:                       194.45\n",
      "Time:                        04:04:04   Pearson chi2:                     165.\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):             0.1655\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -12.3508      2.629     -4.698      0.000     -17.503      -7.199\n",
      "width          0.4972      0.102      4.887      0.000       0.298       0.697\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define model formula\n",
    "formula = 'y ~ width'\n",
    "\n",
    "# Define probability distribution for the response variable for \n",
    "# the linear (LM) and logistic (GLM) model\n",
    "family_LM = sm.families.Gaussian()\n",
    "family_GLM = sm.families.Binomial()\n",
    "\n",
    "# Define and fit a linear regression model\n",
    "model_LM = glm(formula = formula, data = crab, family = family_LM).fit()\n",
    "print(model_LM.summary())\n",
    "\n",
    "# Define and fit a logistic regression model\n",
    "model_GLM = glm(formula = formula, data = crab, family = family_GLM).fit()\n",
    "print(model_GLM.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a165782-d01a-4e29-ba87-a72b4ee90dba",
   "metadata": {},
   "source": [
    "## Comparing predicted values\n",
    "### In the previous exercise, you have fitted both a linear and a GLM (logistic) regression model using crab data, predicting ywith width. In other words, you wanted to predict the probability that the female has a satellite crab nearby given her width.\n",
    "\n",
    "### In this exercise, you will further examine the estimated probabilities (the output) from the two models and try to deduce if the linear fit would be suitable for the problem at hand.\n",
    "### The usual practice is to test the model on new, unseen, data. Such dataset is called test sample.\n",
    "### The test sample has been created for you and loaded in the workspace. Note that you need test values for all variables present in the model, which in this example is width.\n",
    "### The crab dataset has been preloaded in the workspace.\n",
    "\n",
    "### Instructions\n",
    "-    Using print() view the test set.\n",
    "-    Using the test sample, compute estimated probabilities using .predict() on the fitted linear model model_LM and save as pred_lm. Also, compute estimated probabilities using .predict() on the fitted GLM (logistic) model saved as model_GLM and save as pred_glm.\n",
    "-    Using pandas DataFrame() combine predictions from both models and save as predictions.\n",
    "-    Concatenate the test and predictions and save as all_data. View all_data using print()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2517580-6f0f-4721-b34d-24eed9ab9914",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({\"width\": [17.8, 24.6, 28.1, 32.0, 33.7], \"y\": [0, 0, 1, 1, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0506369-8d24-4d31-a8f6-035a2d23cb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   width  y\n",
      "0   17.8  0\n",
      "1   24.6  0\n",
      "2   28.1  1\n",
      "3   32.0  1\n",
      "4   33.7  1\n",
      "   width  y   Pred_LM  Pred_GLM\n",
      "0   17.8  0 -0.136287  0.029309\n",
      "1   24.6  0  0.486122  0.470299\n",
      "2   28.1  1  0.806480  0.834983\n",
      "3   32.0  1  1.163450  0.972363\n",
      "4   33.7  1  1.319052  0.987941\n"
     ]
    }
   ],
   "source": [
    "# View test set\n",
    "print(test)\n",
    "\n",
    "# Compute estimated probabilities for linear model: pred_lm\n",
    "pred_lm = model_LM.predict(test)\n",
    "\n",
    "# Compute estimated probabilities for GLM model: pred_glm\n",
    "pred_glm = model_GLM.predict(test)\n",
    "\n",
    "# Create dataframe of predictions for linear and GLM model: predictions\n",
    "predictions = pd.DataFrame({'Pred_LM': pred_lm, 'Pred_GLM': pred_glm})\n",
    "\n",
    "# Concatenate test sample and predictions and view the results\n",
    "all_data = pd.concat([test, predictions], axis = 1)\n",
    "print(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166e53bb-12f2-413e-816f-2b643df52477",
   "metadata": {},
   "source": [
    "## Model fitting step-by-step\n",
    "### In the video lecture, you learned the key components for fitting a GLM in Python using the statsmodels package. In this exercise you will define the components of the GLM step by step and finally fit the model by calling the .fit() method.\n",
    "\n",
    "### The dataset which you will use is on the contamination of groundwater with arsenic in Bangladesh where we want to model the household decision on switching the current well.\n",
    "### The columns in the dataset are:\n",
    "-    switch: 1 if the change of the current well occurred; 0 otherwise\n",
    "-    arsenic: The level of arsenic contamination in the well\n",
    "-    distance: Distance to the closest known safe well\n",
    "-    education: Years of education of the head of the household\n",
    "-    Dataset wells has been preloaded in the workspace.\n",
    "\n",
    "### Instructions\n",
    "-    Create a regression formula where switch is predicted by distance100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe9db4a9-a712-486f-b53d-e168b0ae96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wells = pd.read_csv(\"data/wells.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66368bb0-f779-4f3b-b7c8-fe2a1645976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the formula the the logistic model\n",
    "model_formula = 'switch ~ distance100'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a57c985-95fd-4d79-95e7-13000dd5221b",
   "metadata": {},
   "source": [
    "-    Define the link function using logit for the Binomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bed6af9-1af5-47f3-8703-315833973077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/statsmodels/genmod/families/links.py:13: FutureWarning: The logit link alias is deprecated. Use Logit instead. The logit link alias will be removed after the 0.15.0 release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the formula the the logistic model\n",
    "model_formula = 'switch ~ distance100'\n",
    "\n",
    "# Define the correct probability distribution and the link function of the response variable\n",
    "link_function = sm.families.links.logit\n",
    "model_family = sm.families.Binomial(link = link_function())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12497940-1c42-43f4-862f-df60f6a46493",
   "metadata": {},
   "source": [
    "-    With the datasets wells, fit the model using the glm() with the previously defined formula and family.\n",
    "-    Fit the model using the .fit() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61ae6892-c8ac-4948-aefc-e7302885b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the formula the the logistic model\n",
    "model_formula = 'switch ~ distance100'\n",
    "\n",
    "# Define the correct probability distribution and the link function of the response variable\n",
    "link_function = sm.families.links.logit()\n",
    "model_family = sm.families.Binomial(link = link_function)\n",
    "\n",
    "# Fit the model\n",
    "wells_fit = glm(formula = model_formula, \n",
    "                 data = wells, \n",
    "                 family = model_family).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbde52a5-8e46-4730-b931-f66566d92574",
   "metadata": {},
   "source": [
    "## Results of the model fit using summary()\n",
    "### In the previous exercise you fitted a logistic regression model wells_fit using glm() and .fit(). The second step after fitting the model is to examine the model results. To do this you will use the .summary() function, which provides an overview of the model coefficients and how well they fit, along with several other statistical measures.\n",
    "\n",
    "### In the lessons to come, you will learn how to interpret the model output and the details of the given statistical measures and how to interpret them.\n",
    "\n",
    "### The model wells_fit has been preloaded in the workspace.\n",
    "\n",
    "### Instructions\n",
    "-    Using summary(), view the model summary from wells_fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "767f019e-1974-4ccf-9aca-8310f53181d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 switch   No. Observations:                 3010\n",
      "Model:                            GLM   Df Residuals:                     3008\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2030.6\n",
      "Date:                Wed, 13 Mar 2024   Deviance:                       4061.3\n",
      "Time:                        02:21:56   Pearson chi2:                 3.01e+03\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):            0.01409\n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       0.6108      0.060     10.104      0.000       0.492       0.729\n",
      "distance100    -0.6291      0.098     -6.446      0.000      -0.820      -0.438\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "# View the results of the wells_fit model\n",
    "print(wells_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ec3df-f2e2-4397-9629-657ae04866e2",
   "metadata": {},
   "source": [
    "## Extracting parameter estimates\n",
    "### Coefficient estimates are generally of main interest in a regression model. In the previous exercise you learned how to view the results of the model fit and hence the coefficient values along with their corresponding statistics. In this exercise you will learn how to extract the coefficients from the model object.\n",
    "\n",
    "### The attribute .params contains the coefficients of the fitted model, starting with the intercept value. To compute a 95% confidence interval for the coefficients you can use the method .conf_int() of the fitted model wells_fit.\n",
    "\n",
    "### Recall that the model you fitted was saved as wells_fit and as such is loaded in your workspace.\n",
    "\n",
    "### Instructions\n",
    "-    Save the coefficients as intercept and slope using the .params attribute.\n",
    "-    Print the saved intercept and slope.\n",
    "-    Extract and print 95% confidence intervals for the coefficients using .conf_int()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97eeebe8-9f0d-4037-8c1f-3bc6e5eb9363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept = 0.6108118803818956\n",
      "Slope = -0.629080847955768\n",
      "                    0         1\n",
      "Intercept    0.492327  0.729297\n",
      "distance100 -0.820345 -0.437816\n"
     ]
    }
   ],
   "source": [
    "# Extract coefficients from the fitted model wells_fit\n",
    "intercept, slope = wells_fit.params\n",
    "\n",
    "# Print coefficients\n",
    "print('Intercept =', intercept)\n",
    "print('Slope =', slope)\n",
    "\n",
    "# Extract and print confidence intervals\n",
    "print(wells_fit.conf_int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea157401-3a6e-459d-9f07-192125501115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
