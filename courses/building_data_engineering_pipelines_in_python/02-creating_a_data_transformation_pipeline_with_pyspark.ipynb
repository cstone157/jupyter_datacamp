{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5adb63bd-9619-4935-b399-2d6576f16d4c",
   "metadata": {},
   "source": [
    "## Reading a CSV file\n",
    "\n",
    "Loading the data is the first step in building a data transformation pipeline. “Comma separated values” (CSV) is a file commonly used file format for data exchange. You’re now going to use Spark to read a CSV file.\n",
    "\n",
    "You’ve seen in the videos how to load landing/prices.csv. Now let’s do the same for landing/ratings.csv, step by step. Remember, the actual data lake is made available to you under ~/workspace/mnt/data_lake.\n",
    "\n",
    "A SparkSession named spark has already been loaded for you.\n",
    "\n",
    "### Instructions\n",
    "    - Create a DataFrameReader object using the spark.read property.\n",
    "    - Make the reader object use the header of the CSV file to name the columns automatically, by passing in the correct keyword arguments to the reader’s .options() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4324c300-0783-43e1-91bb-85d42fc81343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a csv file and set the headers\n",
    "df = (spark.read\n",
    "      .options(header=\"true\")\n",
    "      .csv(\"/home/repl/workspace/mnt/data_lake/landing/ratings.csv\"))\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535270b-3807-4a99-8a76-374595650142",
   "metadata": {},
   "source": [
    "## Defining a schema\n",
    "\n",
    "In the last exercise, you read a CSV file using PySpark. Because you didn’t define a schema, all column values were parsed as strings which can be cumbersome and inefficient to process. You are usually better off defining the data types in a schema yourself.\n",
    "\n",
    "To do this, you use classes from the pyspark.sql.types module. Its StructType() class expects a list of StructField() instances that allow you to add fields to a schema. Various other types, such as ByteType() and IntegerType() are also defined in this module and can be used to specify the data types of each field. In this exercise, all of these classes have been imported for you.\n",
    "\n",
    "In the ratings.csv dataset from the previous exercise, the rating values in the columns “absorption_rate” and “comfort” are expressed on a scale from 1 to 5, like with Amazon’s web store. Because of that, they easily fit into a ByteType(), which can hold values between -128 and 127. The other columns are better left as StringType()s.\n",
    "\n",
    "Feel free to explore the previous Spark DataFrame in the console using df.show() so you can map each column to the correct type.\n",
    "\n",
    "### Instructions\n",
    "    - Define the schema for the spreadsheet that has the columns “brand”, “model”, “absorption_rate” and “comfort”, in that order.\n",
    "    - Pass the predefined schema while loading the CSV file using the .schema() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397125f-5e4e-4904-991a-7e5278fc047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema\n",
    "schema = StructType([\n",
    "  StructField(\"brand\", StringType(), nullable=False),\n",
    "  StructField(\"model\", StringType(), nullable=False),\n",
    "  StructField(\"absorption_rate\", ByteType(), nullable=True),\n",
    "  StructField(\"comfort\", ByteType(), nullable=True)\n",
    "])\n",
    "\n",
    "better_df = (spark\n",
    "             .read\n",
    "             .options(header=\"true\")\n",
    "             # Pass the predefined schema to the Reader\n",
    "             .schema(schema)\n",
    "             .csv(\"/home/repl/workspace/mnt/data_lake/landing/ratings.csv\"))\n",
    "pprint(better_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a89f6b-ec4a-485c-9f4b-a0a44916472a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09fbd86-42d8-4bd1-ad33-54fc7a2a2b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f772420-e4a8-4e50-96e7-f0fa5381e48b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204a4c8-6d2b-4602-ae53-28a603a9191a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c6ce357-0293-4b27-b7dc-74736e843136",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b118046-2cb4-41ad-9924-438a743bb752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78fa521f-93bd-4825-bd34-6fd1760b4012",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd651ff-56d5-4778-8ae5-02ee9dba85f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e966b12-1371-4b24-b582-8b5dfc50624b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160c2070-5010-4ab5-9229-ae5c84d95ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f3ca463-0240-4204-9747-da69b924c54f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cd806e-a0dd-4529-bdc5-3d3897c31ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90ea14e2-7c58-40f6-9350-381243f9c3f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7230b0be-903e-4643-999a-7cfb33da3ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cd0de73-2f9f-4e09-af9f-8e5d10a6e5ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f6358f-68fc-4107-9bca-d1eadc47fcb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
