{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ebc463-ecaf-4cf8-bc3e-f2c5f4aa0657",
   "metadata": {},
   "source": [
    "## Matrix sparsity\n",
    "\n",
    "A common challenge with real-world ratings data is that most users will not have rated most items, and most items will only have been rated by a small number of users. This results in a very empty or sparse DataFrame.\n",
    "\n",
    "In this exercise, you will calculate how sparse the movie_lens ratings data is by counting the number of occupied cells and compare it to the size of the full DataFrame. The DataFrame user_ratings_df that you have used in previous exercises, containing a row per user and a column per movie, has been loaded for you.\n",
    "\n",
    "### Instructions\n",
    "    - Count the number of non-empty cells in user_ratings_df and store the result as sparsity_count.\n",
    "    - Count the total number of cells in the user_ratings_df DataFrame and store it as full_count.\n",
    "    - Calculate the sparsity of the DataFrame by dividing the number of non-empty cells by the total number of cells and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a4ad9-d5cf-469d-9c6d-7da18ad9282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occupied cells\n",
    "sparsity_count = user_ratings_df.isnull().values.sum()\n",
    "\n",
    "# Count all cells\n",
    "full_count = user_ratings_df.size\n",
    "\n",
    "# Find the sparsity of the DataFrame\n",
    "sparsity = sparsity_count / full_count\n",
    "print(sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de2e8bb-3671-4e09-b1fa-877882f6c745",
   "metadata": {},
   "source": [
    "## Limited data in your rows\n",
    "\n",
    "This data sparsity can cause an issue when using techniques like K-nearest neighbors as discussed in the last chapter. KNN needs to find the k most similar users that have rated an item, but if only less than or equal to k users have given an item the rating, all ratings will be the \"most similar\".\n",
    "\n",
    "In this exercise, you will count how often each movie in the user_ratings_df DataFrame has been given a rating, and then see how many have only one or two ratings.\n",
    "\n",
    "### Instructions 1/3\n",
    "    - Count the number of non-empty cells in each column of user_ratings_df and store it as occupied_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b123322-7ed9-4571-b2c0-108899332e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occupied cells per column\n",
    "occupied_count = user_ratings_df.notnull().sum()\n",
    "print(occupied_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a190be86-9fe6-4ac4-a922-6f41681d271e",
   "metadata": {},
   "source": [
    "### Instructions 2/3\n",
    "    - Sort occupied_count from low to high. Looking at the resulting sorted Series, note the number of movies with one review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762fafa5-92a7-490f-be6c-c155b21855f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occupied cells per column\n",
    "occupied_count = user_ratings_df.notnull().sum()\n",
    "\n",
    "# Sort the resulting series from low to high\n",
    "sorted_occupied_count = occupied_count.sort_values()\n",
    "print(sorted_occupied_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67498b92-f0cd-484a-8940-2ae2fb12df11",
   "metadata": {},
   "source": [
    "### Instructions 3/3\n",
    "    - Create a histogram of the sorted_occupied_count Series you just created. matplotlib.pyplothas been loaded as plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae461a-c99f-4d38-905c-cc941ddd63e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occupied cells per column\n",
    "occupied_count = user_ratings_df.notnull().sum()\n",
    "\n",
    "# Sort the resulting series from low to high\n",
    "sorted_occupied_count = occupied_count.sort_values()\n",
    "\n",
    "# Plot a histogram of the values in sorted_occupied_count\n",
    "sorted_occupied_count.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f535e480-bb6d-463e-9207-2ec1e7877f9c",
   "metadata": {},
   "source": [
    "## Information loss in factorization\n",
    "\n",
    "You may wonder how the factors with far fewer columns can summarize a larger DataFrame without loss. In fact, it doesn't â€” the factors we create are generally a close approximation of the data, as it is inevitable for some information to be lost. This means that predicted values might not be exact, but should be close enough to be useful.\n",
    "\n",
    "In this exercise, you will inspect the same original pre-factorization DataFrame from the last exercise loaded as original_df, and compare it to the product of its two factors, user_matrix and item_matrix.\n",
    "\n",
    "### Instructions\n",
    "    - Find the dot product of user_matrix and item_matrix and store it as predictions_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a81176-5f4e-4b37-bdb8-77f120384f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Multiply the user and item matrices\n",
    "predictions_df = np.dot(user_matrix, item_matrix)\n",
    "# Inspect the recreated DataFrame\n",
    "print(predictions_df)\n",
    "\n",
    "# Inspect the original DataFrame and compare\n",
    "print(original_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b111c05-9360-4fc5-a246-d84d0d44afbd",
   "metadata": {},
   "source": [
    "## Normalize your data\n",
    "\n",
    "Before you can find the factors of the ratings matrix using singular value decomposition, you will need to \"de-mean\", or center it, by subtracting each row's mean from each value in that row.\n",
    "\n",
    "In this exercise, you will begin prepping the movie rating DataFrame you have been working with in order to be able to perform Singular value decomposition.\n",
    "\n",
    "user_ratings_df contains a row per user and a column for each movie and has been loaded for you.\n",
    "\n",
    "### Instructions\n",
    "    - Find the average rating each user has given across all the movies they have seen and store these values as avg_ratings.\n",
    "    - Subtract the row averages from their respective rows and store the result as user_ratings_centered.\n",
    "    - Finally, fill in all missing values in user_ratings_centered with zeros.\n",
    "    - Print the average of each column in user_ratings_centered to show they have been de-meaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a184e5-ca32-4a8b-abb0-483d83df1606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average rating for each user \n",
    "avg_ratings = user_ratings_df.mean(axis=1)\n",
    "\n",
    "# Center each user's ratings around 0\n",
    "user_ratings_centered = user_ratings_df.sub(avg_ratings, axis=1)\n",
    "\n",
    "# Fill in all missing values with 0s\n",
    "user_ratings_centered.fillna(0, inplace=True)\n",
    "\n",
    "# Print the mean of each column\n",
    "print(user_ratings_centered.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c325def4-e642-43d2-a19d-c21cebbc27de",
   "metadata": {},
   "source": [
    "## Decomposing your matrix\n",
    "\n",
    "Now that you have prepped your data by centering it and filling in the remaining empty values with 0, you can get around to finding your data's factors. In this exercise, you will break the user_ratings_centered data you generated in the last exercise into 3 factors: U, sigma, and Vt.\n",
    "\n",
    "    - U is a matrix with a row for each user\n",
    "    - Vt has a column for each movie\n",
    "    - sigma is an array of weights that you will need to convert to a diagonal matrix\n",
    "\n",
    "The user_ratings_centered that you created in the last lesson has been loaded for you.\n",
    "\n",
    "### Instructions 1/2\n",
    "    - Import svds from scipy.sparse.linalg.\n",
    "    - Decompose user_ratings_pivot_centered into its factor matrices: U, sigma and Vt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df792209-4ec2-4f26-8767-ac8deddc05e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries \n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np\n",
    "\n",
    "# Decompose the matrix\n",
    "U, sigma, Vt = svds(user_ratings_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afb8daf-6a63-4ccf-8ec0-7aa5ec8f18af",
   "metadata": {},
   "source": [
    "### Instructions 2/2\n",
    "    - Convert the sigma array into a diagonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940548f2-96d9-4eb9-9ea8-d81f93de6ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries \n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np\n",
    "\n",
    "# Decompose the matrix\n",
    "U, sigma, Vt = svds(user_ratings_centered)\n",
    "\n",
    "# Convert sigma into a diagonal matrix\n",
    "sigma = np.diag(sigma)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30558f1f-715b-4b01-bcae-92c69745cbe2",
   "metadata": {},
   "source": [
    "## Recalculating the matrix\n",
    "\n",
    "Now that you have your three factor matrices, you can multiply them back together to get complete ratings data without missing values. In this exercise, you will use numpy's dot product function to multiply U and sigma first, then the result by Vt. You will then be able add the average ratings for each row to find your final ratings.\n",
    "\n",
    "U, sigma, Vt, avg_ratings, and user_ratings_df from the previous exercise have been loaded for you. Also, numpy has been loaded as np.\n",
    "\n",
    "### Instructions 1/4\n",
    "    - Find the dot product of the matrix U and sigma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7662e91f-c33c-4b5c-bdd5-e442958fa697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot product of U and sigma\n",
    "U_sigma = np.dot(U, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecaa14a-c8ed-43e9-8dcf-4f00140866f2",
   "metadata": {},
   "source": [
    "### Instructions 2/4\n",
    "    - Find the dot product of U_sigma and Vt and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e3c285-0277-4110-b521-ee310961cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot product of U and sigma\n",
    "U_sigma = np.dot(U, sigma)\n",
    "\n",
    "# Dot product of result and Vt\n",
    "U_sigma_Vt = np.dot(U_sigma, Vt)\n",
    "\n",
    "# Print the result\n",
    "print(U_sigma_Vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71064123-3ad9-4fc5-8110-1e63f8d8eb3c",
   "metadata": {},
   "source": [
    "### Instructions 3/4\n",
    "    - Reshape the values of avg_ratings and add them back onto U_sigma_Vt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef934c6-ff14-4b0a-ab84-e47dd6d813e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot product of U and sigma\n",
    "U_sigma = np.dot(U, sigma)\n",
    "\n",
    "# Dot product of result and Vt\n",
    "U_sigma_Vt = np.dot(U_sigma, Vt)\n",
    "\n",
    "# Add the row means back contained in avg_ratings\n",
    "uncentered_ratings = U_sigma_Vt + avg_ratings.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c1467-4fb2-4d7a-932e-77323cad282c",
   "metadata": {},
   "source": [
    "### Instructions 4/4\n",
    "    - Create a DataFrame of the results using the original index and column names from user_ratings_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12809b13-8c59-48a3-9199-8803bf5da95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot product of U and sigma\n",
    "U_sigma = np.dot(U, sigma)\n",
    "\n",
    "# Dot product of result and Vt\n",
    "U_sigma_Vt = np.dot(U_sigma, Vt)\n",
    "\n",
    "# Add back on the row means contained in avg_ratings\n",
    "uncentered_ratings = U_sigma_Vt + avg_ratings.values.reshape(-1, 1)\n",
    "\n",
    "# Create DataFrame of the results\n",
    "calc_pred_ratings_df = pd.DataFrame(uncentered_ratings, \n",
    "                                    index=user_ratings_df.index,\n",
    "                                    columns=user_ratings_df.columns\n",
    "                                   )\n",
    "# Print both the recalculated matrix and the original \n",
    "print(calc_pred_ratings_df)\n",
    "print(original_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bfcbcf-c3ad-4d2b-8467-0fc1ceb34685",
   "metadata": {},
   "source": [
    "## Making recommendations with SVD\n",
    "\n",
    "Now that you have the recalculated matrix with all of its gaps filled in, the next step is to use it to generate predictions and recommendations.\n",
    "\n",
    "Using calc_pred_ratings_df that you generated in the last exercise, with all rows and columns filled, find the movies that User_5 is most likely to enjoy.\n",
    "\n",
    "### Instructions\n",
    "    - Find the highest ranked movies for User_5 by sorting all the reviews generated for User_5 from high to low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d44035-f58d-4a8d-8f34-9decac9301b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the ratings of User 5 from high to low\n",
    "user_5_ratings = calc_pred_ratings_df.loc['User_5',:].sort_values(ascending=False)\n",
    "\n",
    "print(user_5_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c5a40-e94c-407e-a5cc-5302139c6de9",
   "metadata": {},
   "source": [
    "## Comparing recommendation methods\n",
    "\n",
    "In this course, you have predicted how you believe a user would rate movies they have not seen using multiple different methods (basic average ratings, KNN, matrix factorization). In this final exercise, you'll work through a comparison of the averaged ratings and matrix factorization using the mean_squared_error() as the measure of how well they are performing. The predictions based on averages have been loaded as avg_pred_ratings_df while the calculated predictions have been loaded as calc_pred_ratings_df. The ground truth values have been loaded as act_ratings_df.\n",
    "\n",
    "Finally, the mean_squared_error() function has been imported for your use from sklearn.metrics.\n",
    "\n",
    "### Instructions\n",
    "    - Extract rows 0-20 and columns 0-100 (the areas that you want to compare) in the act_ratings_df, avg_pred_ratings_df, and calc_pred_ratings_df DataFrames.\n",
    "    - Create a mask of the actual_values DataFrame that targets only non-empty cells.\n",
    "    - Find the mean squared error between the two predictions and the ground truth values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c74c0-64cb-45c6-954e-04bbd3e0163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ground truth to compare your predictions against\n",
    "actual_values = act_ratings_df.iloc[:20, :100].values\n",
    "avg_values = avg_pred_ratings_df.iloc[:20, :100].values\n",
    "predicted_values = calc_pred_ratings_df.iloc[:20, :100].values\n",
    "\n",
    "# Create a mask of actual_values to only look at the non-missing values in the ground truth\n",
    "mask = ~np.isnan(actual_values)\n",
    "\n",
    "# Print the performance of both predictions and compare\n",
    "print(mean_squared_error(actual_values[mask], avg_values[mask], squared=False))\n",
    "print(mean_squared_error(actual_values[mask], predicted_values[mask], squared=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
