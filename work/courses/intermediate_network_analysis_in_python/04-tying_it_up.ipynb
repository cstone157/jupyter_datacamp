{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b3a93a-301f-418b-a6f2-8c8ed336622b",
   "metadata": {},
   "source": [
    "## Create a graph from the pandas DataFrame\n",
    "\n",
    "Let's start by creating a graph from a pandas DataFrame. In this exercise, you'll create a new bipartite graph by looping over the edgelist (which is a DataFrame object).\n",
    "\n",
    "For simplicity's sake, in this graph construction procedure, any edge between a student and a forum node will be the 'last' edge (in time) that a student posted to a forum over the entire time span of the dataset, though there are ways to get around this.\n",
    "\n",
    "Additionally, to shorten the runtime of the exercise, we have provided a sub-sampled version of the edge list as data. Explore it in the IPython Shell to familiarize yourself with it.\n",
    "\n",
    "### Instructions\n",
    "    - Instantiate a new Graph called G.\n",
    "    - Add nodes from each of the partitions. Use the .add_nodes_from() method to do this. The two partitions are 'student' and 'forum'. To add nodes from the 'student' partition, for example, the arguments to .add_nodes_from() would be data['student'] and bipartite='student'.\n",
    "    - Add in each edge along with the date the edge was created. To do this, use the .add_edge() method inside the loop, with the arguments d['student'], d['forum'], and date=d['date']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0cdc79-e6cf-4a28-bfb7-3102419f1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Instantiate a new Graph: G\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes from each of the partitions\n",
    "G.add_nodes_from(data['student'], bipartite='student')\n",
    "G.add_nodes_from(data['forum'], bipartite='forum')\n",
    "\n",
    "# Add in each edge along with the date the edge was created\n",
    "for r, d in data.iterrows():\n",
    "    G.add_edge(d['student'], d['forum'], date=d['date']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f29efa-94b9-44b7-aa07-d150630dcff6",
   "metadata": {},
   "source": [
    "## Visualize the degree centrality distribution of the students projection\n",
    "\n",
    "In this exercise, you will visualize the degree centrality distribution of the students projection. This is a recap of two previous concepts you've learned: degree centralities, and projections.\n",
    "\n",
    "### Instructions\n",
    "    - Get the nodes of the 'student' partition into a list called student_nodes.\n",
    "        - Use a list comprehension to do this, iterating over all the nodes of G (including the metadata), and checking to see if the 'bipartite' keyword of d equals 'student'.\n",
    "    - Create the students nodes projection as a graph called G_students. Use the nx.bipartite.projected_graph() function to do this. Be sure to specify the keyword argument nodes=student_nodes.\n",
    "    - Calculate the degree centrality of G_students using nx.degree_centrality(). Store the result as dcs.\n",
    "    - Plot the histogram of degree centrality values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f2139d-6df2-4f11-a7b5-5306a2c3e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Get the student partition's nodes: student_nodes\n",
    "student_nodes = [n for n, d in G.nodes(data=True) if d['bipartite'] == 'student']\n",
    "\n",
    "# Create the students nodes projection as a graph: G_students\n",
    "G_students = nx.bipartite.projected_graph(G, nodes=student_nodes)\n",
    "\n",
    "# Calculate the degree centrality using nx.degree_centrality: dcs\n",
    "dcs = nx.degree_centrality(G_students)\n",
    "\n",
    "# Plot the histogram of degree centrality values\n",
    "plt.hist(list(dcs.values()))\n",
    "plt.yscale('log')  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c3774f-1fca-4538-ac49-b063dcede625",
   "metadata": {},
   "source": [
    "## Visualize the degree centrality distribution of the forums projection\n",
    "\n",
    "This exercise is also to reinforce the concepts of degree centrality and projections. This time round, you'll plot the degree centrality distribution for the 'forum' projection. Follow the same steps as in the previous exercise!\n",
    "\n",
    "### Instructions\n",
    "    - Get the nodes of the 'forum' partition into a list called forum_nodes.\n",
    "    - Create the forums nodes projection as a graph called G_forum.\n",
    "    - Calculate the degree centrality of G_forum using nx.degree_centrality(). Store the result as dcs.\n",
    "    - Plot the histogram of degree centrality values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6583f2-f19e-4582-b8ed-8d17f3c6b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx\n",
    "\n",
    "# Get the forums partition's nodes: forum_nodes\n",
    "forum_nodes = [n for n, d in G.nodes(data=True) if d['bipartite'] == 'forum']\n",
    "\n",
    "# Create the forum nodes projection as a graph: G_forum\n",
    "G_forum = nx.bipartite.projected_graph(G, nodes=forum_nodes)\n",
    "\n",
    "# Calculate the degree centrality using nx.degree_centrality: dcs\n",
    "dcs = nx.degree_centrality(G_forum)\n",
    "\n",
    "# Plot the histogram of degree centrality values\n",
    "plt.hist(list(dcs.values()))\n",
    "plt.yscale('log') \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b69af0c-8c1b-4709-9217-6f944e379d1e",
   "metadata": {},
   "source": [
    "## Time filter on edges\n",
    "\n",
    "You're now going to practice filtering the graph using a conditional as applied to the edges. This will help you gain practice and become comfortable with list comprehensions that contain conditionals.\n",
    "\n",
    "To help you with the exercises, remember that you can import datetime objects from the datetime module. On the graph, the metadata has a date key that is paired with a datetime object as a value.\n",
    "\n",
    "### Instructions\n",
    "    - Instantiate a new graph called G_sub.\n",
    "    - Add nodes from the original graph (including the node metadata), using the .add_nodes_from() method.\n",
    "    - Add edges using a list comprehension with one conditional on the edge dates, that the date of the edge is earlier than 2004-05-16. To do this:\n",
    "        - Use the .add_edges_from() method with a list comprehension as the argument.\n",
    "        - The output expression of the list comprehension is (u, v, d). Iterate over all the edges of G and check whether d['date'] is less than datetime(2004, 5, 16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0968538b-47d3-46e0-8582-71271af8550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "\n",
    "# Instantiate a new graph: G_sub\n",
    "G_sub = nx.Graph()\n",
    "\n",
    "# Add nodes from the original graph\n",
    "G_sub.add_nodes_from(G.nodes(data=True), bipartite='student')\n",
    "\n",
    "# Add edges using a list comprehension with one conditional on the edge dates, that the date of the edge is earlier than 2004-05-16.\n",
    "G_sub.add_edges_from([(u, v, d) for u, v, d in G.edges(data=True) if d['date'] < datetime(2004,5,16)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec30545-8299-48f0-bdec-fd519e7b41cb",
   "metadata": {},
   "source": [
    "## Visualize filtered graph using nxviz\n",
    "\n",
    "Here, you'll visualize the filtered graph using a circos plot. The circos plot is a natural choice for this visualization, as you can use node grouping and coloring to visualize the partitions, while the circular layout preserves the aesthetics of the visualization.\n",
    "\n",
    "### Instructions\n",
    "    - Compute degree centrality scores of each node using the bipartite module degree centralities, but based on the degree centrality in the original graph.\n",
    "        - Use the nx.bipartite.degree_centrality() function for this, with the arguments G and nodes=forum_nodes.\n",
    "    - Create a new circos plot with nodes colored and grouped (parameters node_color_by and group_by) by their partition label ('bipartite'), and ordered (parameter sort_by) by their degree centrality ('dc') and display it.\n",
    "        - To ensure that the nodes are visible when displayed, we have included the argument node_enc_kwargs={'radius': 10}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106db68-cff6-462b-9e09-19f31655dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from nxviz import circos\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute degree centrality scores of each node\n",
    "dcs = nx.bipartite.degree_centrality(G, nodes=forum_nodes)\n",
    "for n, d in G_sub.nodes(data=True):\n",
    "    G_sub.nodes[n]['dc'] = dcs[n]\n",
    "\n",
    "# Create the circos plot: c\n",
    "c = circos(G_sub, node_color_by=\"bipartite\", group_by=\"bipartite\", sort_by=\"dc\", node_enc_kwargs={'radius': 5})\n",
    "\n",
    "# Display the plot\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970ece59-8bc8-40ed-9ac3-29ac5d0a1912",
   "metadata": {},
   "source": [
    "## Plot number of posts being made over time\n",
    "\n",
    "Let's recap how you can plot evolving graph statistics from the graph data. First off, you will use the graph data to quantify the number of edges that show up within a chunking time window of td days, which is 2 days in the exercise below.\n",
    "\n",
    "The datetime variables dayone and lastday have been provided for you.\n",
    "\n",
    "### Instructions\n",
    "    - Define a timedelta of 2 days using the timedelta() function and specifying an argument for the days parameter.\n",
    "    - Inside the while loop:\n",
    "        - Filter edges such that they are within the sliding time window. Use a list comprehension to do this, where the output expression is (u, v, d), the iterable is G.edges(data=True), and there are two conditions: if d['date'] is >= curr_day and < than curr_day + td.\n",
    "        - Append the number of edges (use the len() function to help you calculate this) to n_posts.\n",
    "        - Increment curr_day by the time delta td.\n",
    "    - Make a plot of n_posts using plt.plot()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef493634-d814-4ea1-8a1c-a40e8590d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from datetime import timedelta  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define current day and timedelta of 2 days\n",
    "curr_day = dayone\n",
    "td = timedelta(days=2)\n",
    "\n",
    "# Initialize an empty list of posts by day\n",
    "n_posts = []\n",
    "while curr_day < lastday:\n",
    "    if curr_day.day == 1:\n",
    "        print(curr_day) \n",
    "    # Filter edges such that they are within the sliding time window: edges\n",
    "    edges = [(u, v, d) for u, v, d in G.edges(data=True) if d['date'] >= curr_day and d['date'] < curr_day + td]\n",
    "    \n",
    "    # Append number of edges to the n_posts list\n",
    "    n_posts.append(len(edges))\n",
    "    # Increment the curr_day by the time delta\n",
    "    curr_day += td\n",
    "   \n",
    "# Create the plot \n",
    "plt.plot(n_posts)  \n",
    "plt.xlabel('Days elapsed')\n",
    "plt.ylabel('Number of posts')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e58234-38e7-4710-b203-18afc9637ba2",
   "metadata": {},
   "source": [
    "## Extract the mean degree centrality day-by-day on the students partition\n",
    "\n",
    "Here, you're going to see if the mean degree centrality over all nodes is correlated with the number of edges that are plotted over time. There might not necessarily be a strong correlation, and you'll take a look to see if that's the case.\n",
    "\n",
    "### Instructions\n",
    "    - Instantiate a new graph called G_sub containing a subset of edges.\n",
    "    - Add nodes from G, including the node metadata.\n",
    "    - Add in edges that fulfill the criteria, using the .add_edges_from() method.\n",
    "    - Get the students projection G_student_sub from G_sub using the nx.bipartite.projected_graph() function.\n",
    "    - Compute the degree centrality of the students projection using nx.degree_centrality() (don't use the bipartite version).\n",
    "    - Append the mean degree centrality to the list mean_dcs. Be sure to convert dc.values() to a list first.\n",
    "    - Hit 'Submit Answer' to view the plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231a652-d2a0-434b-bfa3-64a6008ff884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize a new list: mean_dcs\n",
    "mean_dcs = []\n",
    "curr_day = dayone\n",
    "td = timedelta(days=2)\n",
    "\n",
    "while curr_day < lastday:\n",
    "    if curr_day.day == 1:\n",
    "        print(curr_day) \n",
    "    # Instantiate a new graph containing a subset of edges: G_sub\n",
    "    G_sub = nx.Graph()\n",
    "    # Add nodes from G\n",
    "    G_sub.add_nodes_from(G.nodes(data=True))\n",
    "    # Add in edges that fulfill the criteria\n",
    "    G_sub.add_edges_from([(u, v, d) for u, v, d in G.edges(data=True) if d['date'] >= curr_day and d['date'] < curr_day + td])\n",
    "    \n",
    "    # Get the students projection\n",
    "    G_student_sub = nx.bipartite.projected_graph(G_sub, nodes=student_nodes)\n",
    "    # Compute the degree centrality of the students projection\n",
    "    dc = nx.degree_centrality(G_student_sub)\n",
    "    # Append mean degree centrality to the list mean_dcs\n",
    "    mean_dcs.append(np.mean(list(dc.values())))\n",
    "    # Increment the time\n",
    "    curr_day += td\n",
    "    \n",
    "plt.plot(mean_dcs)\n",
    "plt.xlabel('Time elapsed')\n",
    "plt.ylabel('Degree centrality.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decd39d6-30a1-4e0b-8a7e-8396c3ab1a6d",
   "metadata": {},
   "source": [
    "## Find the most popular forums day-by-day: I\n",
    "\n",
    "Great stuff! You're onto the final two exercises - which are really just one long exercise. These will be a good memory workout for your Python programming skills!\n",
    "\n",
    "We're going to see how many forums took the title of \"the most popular forum\" on any given time window.\n",
    "\n",
    "### Instructions\n",
    "    - Instantiate a list to hold the list of most popular forums by day called most_popular_forums.\n",
    "    - Instantiate a list to hold the degree centrality scores of the most popular forums called highest_dcs.\n",
    "    - Instantiate new graph called G_sub and add in the nodes from the original graph G using the .add_nodes_from() method.\n",
    "    - Add in edges from the original graph G that fulfill the criteria (which are exactly the same as in the previous exercise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6fa0e7-fff4-4270-a86f-ccf42fb998e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from datetime import timedelta\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Instantiate a list to hold the list of most popular forums by day: most_popular_forums\n",
    "most_popular_forums = []\n",
    "# Instantiate a list to hold the degree centrality scores of the most popular forums: highest_dcs\n",
    "highest_dcs = []\n",
    "curr_day = dayone  \n",
    "td = timedelta(days=1)  \n",
    "\n",
    "while curr_day < lastday:  \n",
    "    if curr_day.day == 1: \n",
    "        print(curr_day) \n",
    "    # Instantiate new graph: G_sub\n",
    "    G_sub = nx.Graph()\n",
    "    \n",
    "    # Add in nodes from original graph G\n",
    "    G_sub.add_nodes_from(G.nodes(data=True))\n",
    "    \n",
    "    # Add in edges from the original graph G that fulfill the criteria\n",
    "    G_sub.add_edges_from([(u, v, d) for u, v, d in G.edges(data=True) if d['date'] >= curr_day and d['date'] < curr_day + td])\n",
    "    \n",
    "    # CODE CONTINUES ON NEXT EXERCISE\n",
    "    curr_day += td"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724cc157-c8c9-44fd-b104-6ff660d908ca",
   "metadata": {},
   "source": [
    "## Find the most popular forums day-by-day: II\n",
    "\n",
    "Great work with the previous exercise - you had written code that created the time-series graph list. Now, you're going to finish that exercise - that is, you'll find out how many forums had the most popular forum score on a per-day basis!\n",
    "\n",
    "One of the things you will be doing here is a \"dictionary comprehension\" to filter a dictionary. It is very similar to a list comprehension to filter a list, except the syntax looks like: {key: val for key, val in dict.items() if ...}. Keep that in mind!\n",
    "\n",
    "### Instructions\n",
    "    - Get the degree centrality using nx.bipartite.degree_centrality(), with G_sub and forum_nodes as arguments.\n",
    "    - Filter the dictionary such that there's only forum degree centralities. The key: val pair in the output expression should be n, dc. Iterate over dc.items() and check if n is in forum_nodes.\n",
    "    - Identify the most popular forum(s) - should be of highest degree centrality (max(forum_dcs.values())) and its DC value should not be zero.\n",
    "    - Append the highest dc values to highest_dcs.\n",
    "    - Create the plots!\n",
    "        - Use a list comprehension for the first plot, in which you iterate over most_popular_forums (which is a list of lists) using forums as your iterator variable. The output expression should be the number of most popular forums, calculated using len().\n",
    "        - For the second plot, use highest_dcs and plt.plot() to visualize the top degree centrality score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309eaaf0-9172-4d4e-a2c5-bebc648d8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from datetime import timedelta\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "most_popular_forums = []\n",
    "highest_dcs = []\n",
    "curr_day = dayone \n",
    "td = timedelta(days=1)  \n",
    "\n",
    "while curr_day < lastday:  \n",
    "    if curr_day.day == 1:  \n",
    "        print(curr_day)  \n",
    "    G_sub = nx.Graph()\n",
    "    G_sub.add_nodes_from(G.nodes(data=True))   \n",
    "    G_sub.add_edges_from([(u, v, d) for u, v, d in G.edges(data=True) if d['date'] >= curr_day and d['date'] < curr_day + td])\n",
    "    \n",
    "    # Get the degree centrality \n",
    "    dc = nx.bipartite.degree_centrality(G_sub, forum_nodes)\n",
    "    # Filter the dictionary such that there's only forum degree centralities\n",
    "    forum_dcs = {n:dc for n, dc in dc.items() if n in forum_nodes}\n",
    "    # Identify the most popular forum(s) \n",
    "    most_popular_forum = [n for n, dc in forum_dcs.items() if dc == max(forum_dcs.values()) and dc != 0] \n",
    "    most_popular_forums.append(most_popular_forum) \n",
    "    # Store the highest dc values in highest_dcs\n",
    "    highest_dcs.append(max(forum_dcs.values()))\n",
    "    \n",
    "    curr_day += td  \n",
    "    \n",
    "plt.figure(1) \n",
    "plt.plot([len(forums) for forums in most_popular_forums], color='blue', label='Forums')\n",
    "plt.ylabel('Number of Most Popular Forums')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(highest_dcs, color='orange', label='DC Score')\n",
    "plt.ylabel('Top Degree Centrality Score')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
