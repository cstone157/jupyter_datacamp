{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d8366de-d43e-4c7f-8bc6-300ebde81a4d",
   "metadata": {},
   "source": [
    "## Develop a classification model\n",
    "\n",
    "In this exercise, you'll work with the weather dataset and develop a training code to predict rainfall for the next day. The preprocess_dataset.py contains helper functions to pre-process the dataset. Your task is to finish the scaffolded train.py to formulate a high-level model training flow.\n",
    "\n",
    "Feel free to explore the Python files to see the complete implementation of the workflow.\n",
    "\n",
    "NOTE: Use python3 instead of python to run Python scripts.\n",
    "\n",
    "### Ide Exercise Instruction\n",
    "    - Split the pre-processed dataset in train.py file using the train_test_split method from scikit-learn.\n",
    "    - Train the model using the training set, by specifying the correct arguments to the train_model method.\n",
    "    - Calculate test set metrics using the test set, by specifying the correct arguments to the evaluate_model method.\n",
    "    - Save the metrics dictionary into a JSON file using the save_metrics method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782fe57-edb9-476c-b5cd-d08160009aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from metrics_and_plots import plot_confusion_matrix, save_metrics\n",
    "from model import evaluate_model, train_model\n",
    "from utils_and_constants import PROCESSED_DATASET, TARGET_COLUMN\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(TARGET_COLUMN, axis=1)\n",
    "    y = data[TARGET_COLUMN]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def main():\n",
    "    X, y = load_data(PROCESSED_DATASET)\n",
    "    \n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1993)\n",
    "\n",
    "    # Train the model using the training set\n",
    "    model = train_model(X_train, y_train)\n",
    "    \n",
    "    # Calculate test set metrics\n",
    "    metrics = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "    print(\"====================Test Set Metrics==================\")\n",
    "    print(json.dumps(metrics, indent=2))\n",
    "    print(\"======================================================\")\n",
    "\n",
    "    # Save metrics into json file\n",
    "    save_metrics(metrics)\n",
    "    plot_confusion_matrix(model, X_test, y_test)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70146a7e-7861-4949-9f0b-530562fe3b3f",
   "metadata": {},
   "source": [
    "## Setup model training using CML\n",
    "\n",
    "In this exercise, you will use CML GitHub Action to train a Random Forest Classifier to predict rainfall. CML is a GitHub Action that abstracts generating reports for ML experiments.\n",
    "\n",
    "The training will trigger when you open a PR against the main branch. You'll continue working with the weather dataset; the preprocess_dataset.py file contains helper functions to pre-process the dataset as before.\n",
    "\n",
    "The output from running train.py is a metrics.json file containing model metrics, and confusion_matrix.png file containing a plot of the confusion matrix.\n",
    "\n",
    "Your task is to finish the scaffolded .github/workflows/train_cml.yaml to formulate a high-level model training flow.\n",
    "\n",
    "NOTE: Use python3 instead of python to run Python scripts.\n",
    "\n",
    "### Ide Exercise Instruction\n",
    "    - Setup CML GitHub Action iterative/setup-cml@v1.\n",
    "    - Add evaluation metrics data, metrics.json, to the markdown report in the Write CML report step.\n",
    "    - Add confusion matrix plot, confusion_matrix.png , to the markdown report in the Write CML report step.\n",
    "    - Write the correct cml comment subcommand to create a comment in the PR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4bbf5b-3c20-4c42-8823-e7f163f750b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "name: model-training\n",
    "\n",
    "on:\n",
    "  pull_request:\n",
    "    branches: main\n",
    "\n",
    "permissions: write-all\n",
    "\n",
    "jobs:\n",
    "  train_and_report_eval_performance:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - name: Checkout \n",
    "        uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Setup Python\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: 3.9\n",
    "\n",
    "      # Setup CML GitHub Action\n",
    "      - name: Setup CML\n",
    "        uses: iterative/setup-cml@v1\n",
    "          \n",
    "      - name: Train model\n",
    "        run: |\n",
    "          python3 preprocess_dataset.py\n",
    "          python3 train.py\n",
    "\n",
    "      - name: Write CML report\n",
    "        env:\n",
    "          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "        run: |\n",
    "          # Add metrics data to markdown\n",
    "          cat metrics.json >> model_eval_report.md\n",
    "          \n",
    "          # Add confusion matrix plot to markdown\n",
    "          echo \"![confusion matrix plot](./confusion_matrix.png)\" >> model_eval_report.md\n",
    "\n",
    "          # Create comment from markdown report\n",
    "          cml comment create model_eval_report.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d169c-7bd4-4ad4-b8bf-aee2696e3f04",
   "metadata": {},
   "source": [
    "## Data versioning in action\n",
    "\n",
    "Data Version Control (DVC) provides a systematic approach to versioning data, a critical aspect often overlooked. With DVC, you can precisely track changes in your datasets, ensuring reproducibility, collaboration, and troubleshooting ease. It's your safeguard against data-related challenges, fostering trust and efficiency in your data-driven projects.\n",
    "\n",
    "In this exercise, you will practice initializing a DVC project and versioning a dataset. Git has already been initialized for this project.\n",
    "\n",
    "### Ide Exercise Instruction\n",
    "    - Initialize DVC in the workspace.\n",
    "    - Verify that .dvcignore file and .dvc folder are present.\n",
    "    - Add dataset.csv to DVC and examine the contents of dataset.csv.dvc by opening it in the file editor.\n",
    "    - Verify that DVC cache is populated by running find .dvc/cache -type f command in terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb633e-a0f0-4f3c-aaba-f0b6c3b11e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repl:~/workspace$ dvc init\n",
    "# repl:~/workspace$ dvc add dataset.csv\n",
    "# repl:~/workspace$ find .dvc/cache -type "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3b546d-41a1-48f2-91d4-f50c3a4daaaf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502fd074-77c4-4635-8159-c68cb5447277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
