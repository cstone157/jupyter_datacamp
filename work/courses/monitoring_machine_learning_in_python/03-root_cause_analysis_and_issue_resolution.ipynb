{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5be9ee8-3ba4-4a92-b570-34c81747a13c",
   "metadata": {},
   "source": [
    "## Drift in hotel booking dataset\n",
    "\n",
    "In the previous chapter, you calculated the business value and ROC AUC performance for a model that predicts booking cancellations. You noticed a few alerts in the resulting plots, which is why you need to investigate the presence of drift in the analysis data.\n",
    "\n",
    "In this exercise, you will initialize the multivariate drift detection method and compare its results with the performance results calculated in the previous chapter.\n",
    "\n",
    "StandardDeviationThreshold is already imported along with business value, and ROC AUC results stored in the perf_results variable and feature_column_names are already defined.\n",
    "\n",
    "### Instructions\n",
    "    - Initialize the StandardDeviationThreshold method and set std_lower_multiplier to 2 and std_upper_multiplier parameters to 1.\n",
    "    - Add the following feature names country, lead_time, parking_spaces, and hotel. Retain their order.\n",
    "    - Pass previously defined thresholds and feature names to the DataReconstructionDriftCalculator.\n",
    "    - Show the comparison plot featuring both the multivariate drift detection results(mv_results) and the performance results(perf_results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5277ef84-6fcc-4a6e-87a5-06fd32ca30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create standard deviation thresholds\n",
    "stdt = StandardDeviationThreshold(std_lower_multiplier=2, std_upper_multiplier=1)\n",
    "\n",
    "# Define feature columns\n",
    "feature_column_names = ['country', 'lead_time', 'parking_spaces', 'hotel']\n",
    "\n",
    "# Intialize, fit, and show results of multivariate drift calculator\n",
    "mv_calc = nannyml.DataReconstructionDriftCalculator(\n",
    "    column_names=feature_column_names,\n",
    "\tthreshold = stdt,\n",
    "    timestamp_column_name='timestamp',\n",
    "    chunk_period='m')\n",
    "mv_calc.fit(reference)\n",
    "mv_results = mv_calc.calculate(analysis)\n",
    "mv_results.filter(period='analysis').compare(perf_results).plot().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1021b50f-6844-4981-861c-4a361a75d0c8",
   "metadata": {},
   "source": [
    "## Univariate drift detection for hotel booking dataset\n",
    "\n",
    "In the previous exercises, we established using the multivariate drift detection method that the shift in data in January is responsible for the alert in the ROC AUC metric and the negative business value of the model.\n",
    "\n",
    "In this exercise, you will use a univariate drift detection method to find the feature and explanation behind the drift.\n",
    "\n",
    "The reference and analysis sets are already pre-loaded for you.\n",
    "\n",
    "### Instructions\n",
    "    - Specify Wasserstein and Jensen-Shannon method for continuous methods and L-inifity and Chi2 for categorical.\n",
    "    - Fit the reference and calculate results on the analysis set.\n",
    "    - Plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d8a34-9439-4a52-ac9b-eddb6dc4182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize the univariate drift calculator\n",
    "uv_calc = nannyml.UnivariateDriftCalculator(\n",
    "    column_names=feature_column_names,\n",
    "    timestamp_column_name='timestamp',\n",
    "    chunk_period='m',\n",
    "    continuous_methods=['wasserstein', 'jensen_shannon'],\n",
    "    categorical_methods=['l_infinity', 'chi2'],\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "uv_calc.fit(reference)\n",
    "uv_results = uv_calc.calculate(analysis)\n",
    "uv_results.plot().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e754da-df9d-4db5-90cd-19926f91c299",
   "metadata": {},
   "source": [
    "## Ranking the univariate results\n",
    "\n",
    "In the previous exercises, you ended up with eight plots. In this exercise your task is to rank them based on the number of the alerts and the correlation with the ROC AUC performance.\n",
    "\n",
    "The univariate results are pre-loaded and stored in uv_results variable, and performance results are stored in perf_results variable.\n",
    "\n",
    "### Instructions 1/2\n",
    "    - Initialize AlertCountRanker without any initial parameters.\n",
    "    - Call .rank() method and pass the filtered uv_results for Wasserstein and L-infinity methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a580aa-19a1-4728-a17f-3e6d63b854c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the alert count ranker\n",
    "alert_count_ranker = nannyml.AlertCountRanker()\n",
    "alert_count_ranked_features = alert_count_ranker.rank(\n",
    "    uv_results.filter(methods=['wasserstein', 'l_infinity']))\n",
    "\n",
    "display(alert_count_ranked_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2946a9-49fc-4586-9c19-36882637e7fe",
   "metadata": {},
   "source": [
    "### Instructions 2/2\n",
    "    - Initialize CorrelationRanker without any initial parameters.\n",
    "    - Fit correlation ranker with filtered perf_results for reference period.\n",
    "    - Use rank method and pass there filtered uv_results for Wasserstein and L-infinity methods and perf_results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a17453c-334d-4f5b-a3e8-be9a2925c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the alert count ranker\n",
    "alert_count_ranker = nannyml.AlertCountRanker()\n",
    "alert_count_ranked_features = alert_count_ranker.rank(\n",
    "    uv_results.filter(methods=['wasserstein', 'l_infinity']))\n",
    "\n",
    "display(alert_count_ranked_features)\n",
    "\n",
    "# Initialize the correlation ranker\n",
    "correlation_ranker = nannyml.CorrelationRanker()\n",
    "correlation_ranker.fit(perf_results.filter(period='reference'))\n",
    "\n",
    "correlation_ranked_features = correlation_ranker.rank(\n",
    "    uv_results.filter(methods=['wasserstein', 'l_infinity']),\n",
    "    perf_results)\n",
    "display(correlation_ranked_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c4ffbd-2612-486c-90cc-339ab533aba7",
   "metadata": {},
   "source": [
    "## Visualizing drifting features\n",
    "\n",
    "After ranking the univariate results, you know that drift hotel and country features are impacting the model's performance the most. In this exercise, you will look at the drift results and distribution plots of them to determine the root cause of the problem.\n",
    "\n",
    "The results from the univariate drift calculator are stored in the uv_results variable.\n",
    "\n",
    "### Instructions\n",
    "    - Set period argument to analysis for drift_results.\n",
    "    - Pass hotel and country to column_names for drift_results.\n",
    "    - Set kind argument in .plot() method to \"drift\".\n",
    "    - Do the same for distribution_results, except for setting the kind argument in .plot() method to \"distribution\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e09cd1-ad42-48be-9fee-ebcadf0a980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and create drift plots\n",
    "drift_results = uv_results.filter(\n",
    "    period='analysis',\n",
    "    column_names=['hotel', 'country']\n",
    "    ).plot(kind='drift')\n",
    "\n",
    "# Filter and create distribution plots\n",
    "distribution_results = uv_results.filter(\n",
    "    period='analysis',\n",
    "    column_names=['hotel', 'country']\n",
    "    ).plot(kind='distribution')\n",
    "\n",
    "# Show the plots\n",
    "drift_results.show()\n",
    "distribution_results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc165bc-cdd5-46ba-8e03-89d371eb98a1",
   "metadata": {},
   "source": [
    "## Data quality checks\n",
    "\n",
    "As you learned in the previous video, missing values can result in a loss of valuable information and potentially lead to incorrect interpretations. Similarly, the presence of unseen values can also affect your model's confidence.\n",
    "\n",
    "In this exercise, your goal is to explore whether the hotel booking dataset contains missing values and identify any unseen values. The reference and analysis datasets are already loaded, along with the nannyml library.\n",
    "\n",
    "A quick reminder, if you can't recall the column types, you can easily explore the data using the .head() method.\n",
    "\n",
    "### Instructions 1/2\n",
    "    - Initialize the missing value calculator, passing the selected columns to column_names and setting the chunk_period to monthly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d97a2-406c-4d32-9e94-d354a8ba797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define analyzed columns\n",
    "selected_columns = ['country', 'lead_time', 'parking_spaces', 'hotel']\n",
    "\n",
    "# Intialize missing values calculator\n",
    "ms_calc = nannyml.MissingValuesCalculator(\n",
    "    column_names=selected_columns,\n",
    "    chunk_period='m',\n",
    "    timestamp_column_name='timestamp'\n",
    ")\n",
    "\n",
    "# Fit, calculate and plot the results\n",
    "ms_calc.fit(reference)\n",
    "ms_results = ms_calc.calculate(analysis)\n",
    "ms_results.plot().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a184677a-bc9a-4fc4-b2ee-9dde70926998",
   "metadata": {},
   "source": [
    "### Instructions 2/2\n",
    "    - Add two categorical column names country and hotel, initialize the unseen values calculator, and pass the categorical_columns to column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0f6ea9-a014-496a-af94-59a01fbbb4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define analyzed categorical columns\n",
    "categorical_columns = ['country', 'hotel']\n",
    "\n",
    "# Intialize unseen values calculator\n",
    "us_calc = nannyml.UnseenValuesCalculator(\n",
    "  \tcolumn_names=categorical_columns, \n",
    "  \tchunk_period='m', \n",
    "  \ttimestamp_column_name='timestamp'\n",
    ")\n",
    "\n",
    "# Fit, calculate and plot the results\n",
    "us_calc.fit(reference)\n",
    "us_results = us_calc.calculate(analysis)\n",
    "us_results.filter(period='analysis').plot().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458e1ccd-f036-4cf9-8d3e-40821771591c",
   "metadata": {},
   "source": [
    "## Summary statistics\n",
    "\n",
    "Recall from the previous lesson that NannyML provides five methods for tracking statistical changes in your features.\n",
    "\n",
    "In this exercise, you will focus on examining the lead_time feature from the Hotel Booking dataset, which indicates how many days in advance a booking was made. By using summation, median, and standard deviation statistics, you can gain valuable insights into how customer booking behavior has evolved over time.\n",
    "\n",
    "It's important to note that both the reference and analysis sets, as well as the nannyml library, are already pre-loaded and ready for use.\n",
    "\n",
    "### Instructions 1/3\n",
    "    - Define analyzed column to lead time, initialize SummaryStatsSumCalculator, Pass analyzed_column to the column names parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fdae3c-758b-4714-a2e3-876f8b798aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define analyzed column\n",
    "analyzed_column = ['lead_time']\n",
    "\n",
    "# Intialize sum values calculator\n",
    "sum_calc = nannyml.SummaryStatsSumCalculator(\n",
    "    column_names=analyzed_column, \n",
    "    chunk_period='m', \n",
    "    timestamp_column_name='timestamp'\n",
    ")\n",
    "\n",
    "# Fit, calculate and plot the results\n",
    "sum_calc.fit(reference)\n",
    "sum_calc_res = sum_calc.calculate(analysis)\n",
    "sum_calc_res.plot().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee27c731-65a9-476e-ae94-24319ba940fa",
   "metadata": {},
   "source": [
    "### Instructions 2/3\n",
    "    - Initialize SummaryStatsMedianCalculator, pass analyzed_column to the column names parameter, filter results for the only analysis period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d352fef6-d53b-44cc-b273-d74b19949c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define analyzed column\n",
    "analyzed_column = ['lead_time']\n",
    "\n",
    "# Intialize median values calculator\n",
    "med_calc = nannyml.SummaryStatsMedianCalculator(\n",
    "    column_names=analyzed_column, \n",
    "    chunk_period='m', \n",
    "    timestamp_column_name='timestamp'\n",
    ")\n",
    "\n",
    "# Fit, calculate and plot the results\n",
    "med_calc.fit(reference)\n",
    "med_calc_res = med_calc.calculate(analysis)\n",
    "med_calc_res.filter(period='analysis').plot().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dc9e8b-8923-4ef6-a760-c9c9145fc698",
   "metadata": {},
   "source": [
    "### Instructions 3/3\n",
    "    - Initialize SummaryStatsStdCalculator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ac5a7-d587-4636-8c4f-c2cb637af1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define analyzed column\n",
    "analyzed_column = ['lead_time']\n",
    "\n",
    "# Intialize standard deviation values calculator\n",
    "std_calc = nannyml.SummaryStatsStdCalculator(\n",
    "    column_names=analyzed_column, \n",
    "    chunk_period='m', \n",
    "    timestamp_column_name='timestamp'\n",
    ")\n",
    "\n",
    "# Fit, calculate and plot the results\n",
    "std_calc.fit(reference)\n",
    "std_calc_res = std_calc.calculate(analysis)\n",
    "std_calc_res.filter(period=\"analysis\").plot().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07872ec8-e445-4302-93a9-5805e7796198",
   "metadata": {},
   "source": [
    "## Implementing a monitoring workflow\n",
    "\n",
    "Throughout the course, you've learned about the monitoring workflow. The first step is performance monitoring. If there are negative changes, the next steps involve multivariate drift detection to identify if drift caused the performance drop, followed by univariate drift detection to pinpoint the cause in individual features. Once the investigation results are in, you can take steps to resolve the issue.\n",
    "\n",
    "To solidify this knowledge, in the exercise, you'll apply this process to the US Consensus dataset. The reference and analysis datasets are pre-loaded, and you have access to the CBPE estimator, uv_calc univariate calculator, and an alert_count_ranker for feature drift ranking.\n",
    "\n",
    "### Instructions 1/4\n",
    "    - Fit the reference set to the estimator, estimate results on analysis set, and show the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9524e86d-6d81-4f94-ab7e-0baa560f6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the performance\n",
    "estimator.fit(reference)\n",
    "estimated_results = estimator.estimate(analysis)\n",
    "estimated_results.plot().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9be445-bc8c-4d20-a817-e625fff77348",
   "metadata": {},
   "source": [
    "### Instructions 2/4\n",
    "    - Set the chunk_size parameter to 5000 for DataReconstructionDriftCalculator. Next, filter the mv_results for analysis period, then compare them with the estimated_results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b96a7-622f-4469-a063-046f98b60cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(reference)\n",
    "estimated_results = estimator.estimate(analysis)\n",
    "\n",
    "# Calculate multivariate drift\n",
    "mv_calc = nannyml.DataReconstructionDriftCalculator(column_names=features, chunk_size=5000)\n",
    "mv_calc.fit(reference)\n",
    "mv_results = mv_calc.calculate(analysis)\n",
    "mv_results.filter(period='analysis').compare(estimated_results).plot().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e2851c-c2e3-4d41-a51c-a0495f886cbe",
   "metadata": {},
   "source": [
    "### Instructions 3/4\n",
    "    - Use the rank method to rank the features based on the number of alerts in univariate drift results and display the top 5 rows of the alert count ranked features by using the head method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b853df-48bd-4cea-b9b3-f47d90cf9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(reference)\n",
    "estimated_performance = estimator.estimate(analysis)\n",
    "mv_calc = nannyml.DataReconstructionDriftCalculator(column_names=features, chunk_size=5000)\n",
    "mv_calc.fit(reference)\n",
    "mv_results = mv_calc.calculate(analysis)\n",
    "\n",
    "# Calculate univariate drift\n",
    "uv_calculator.fit(reference)\n",
    "uv_results = uv_calculator.calculate(analysis)\n",
    "\n",
    "# Check the most drifting features\n",
    "alert_count_ranked_features = alert_count_ranker.rank(uv_results)\n",
    "display(alert_count_ranked_features.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
