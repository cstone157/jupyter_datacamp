{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45312a1c-f676-4526-be97-fc6bc1ff60a8",
   "metadata": {},
   "source": [
    "## Running an ETL Pipeline\n",
    "\n",
    "Ready to run your first ETL pipeline? Let's get to it!\n",
    "\n",
    "Here, the functions extract(), transform(), and load() have been defined for you. To run this data ETL pipeline, you're going to execute each of these functions. If you're curious, take a peek at what the extract() function looks like.\n",
    "\n",
    "<code>\n",
    "def extract(file_name):\n",
    "    print(f\"Extracting data from {file_name}\")\n",
    "    return pd.read_csv(file_name)\n",
    "</code>\n",
    "\n",
    "### Instructions\n",
    "    - Use the extract() function to extract data from the raw_data.csv file.\n",
    "    - Transform the extracted_data DataFrame using the transform() function.\n",
    "    - Finally, load the transformed_data DataFrame to the cleaned_data SQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd227769-5bd0-4245-bc79-a6ae5c18a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_name):\n",
    "    print(f\"Extracting data from {file_name}.\")\n",
    "    return pd.read_csv(file_name)\n",
    "\n",
    "def transform(data_frame):\n",
    "    print(f\"Transforming {data_frame.shape[0]} rows of raw data.\")\n",
    "\n",
    "def load(data_frame, target_table):\n",
    "  print(f\"Loading cleaned data to {target_table}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f847f8-6904-4449-b2c8-03a53a519fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the raw_data.csv file\n",
    "extracted_data = extract(file_name=\"raw_data.csv\")\n",
    "\n",
    "# Transform the extracted_data\n",
    "transformed_data = transform(data_frame=extracted_data)\n",
    "\n",
    "# Load the transformed_data to cleaned_data.csv\n",
    "load(data_frame=transformed_data, target_table=\"cleaned_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3490bf3c-ff8e-47ca-aaf4-0de20a140055",
   "metadata": {},
   "source": [
    "## ELT in Action\n",
    "\n",
    "Feeling pretty good about running ETL processes? Well, it's time to give ELT pipelines a try. Like before, the extract(), load(), and transform() functions have been defined for you; all you'll have to worry about is running these functions. Good luck!\n",
    "\n",
    "### Instructions\n",
    "    - Use the appropriate ETL function to extract data from the raw_data.csv file.\n",
    "    - Load the raw_data DataFrame into the raw_data table in a data warehouse.\n",
    "    - Call the transform() function to transform the data in the raw_data source table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f1f4d97-d713-4d04-b1ff-0100adfe8bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_name):\n",
    "    print(f\"Extracting data from {file_name}.\")\n",
    "    return pd.read_csv(file_name)\n",
    "\n",
    "def load(data_frame, table_name):\n",
    "    print(f\"Loading cleaned data to {table_name}.\")\n",
    "    data_warehouse.load_table(data_frame, table_name)\n",
    "\n",
    "def transform(source_table, target_table):\n",
    "    data_warehouse.run_sql(f\"\"\"\n",
    "        CREATE TABLE {target_table} AS\n",
    "            SELECT\n",
    "                CONCAT(\"Product ID: \", product_id),\n",
    "            quantity * price\n",
    "        FROM {source_table};\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0469f5a-a06e-465d-b74c-9a8210d0935b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract data from the raw_data.csv file\n",
    "raw_data = extract(file_name=\"raw_data.csv\")\n",
    "\n",
    "# Load the extracted_data to the raw_data table\n",
    "load(data_frame=raw_data, table_name=\"raw_data\")\n",
    "\n",
    "# Transform data in the raw_data table\n",
    "transform(\n",
    "  source_table=\"raw_data\", \n",
    "  target_table=\"cleaned_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719021cd-aaa5-4dc5-8410-e79a3b7251f0",
   "metadata": {},
   "source": [
    "## Building an ETL Pipeline\n",
    "\n",
    "Ready to ratchet up the fun? In this exercise, you'll be responsible for building the rest of the load() function before running each step in the ETL process. The extract() and transform() functions have been defined for you. Good luck!\n",
    "\n",
    "### Instructions\n",
    "    - Complete the load() function by writing the transformed_data DataFrame to a .csv file, using file_name.\n",
    "    - Use the transform() function to clean the extracted_data DataFrame.\n",
    "    - Load transformed_data to the transformed_data.csv file using the load() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c02b37-6794-4bb1-93dc-893a7a08e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_name):\n",
    "    print(\"Extracting data from a source system\")\n",
    "    return pd.DataFrame([{\"item_name\": \"Laptop\", \"quantity\": 11}])\n",
    "\n",
    "def transform(data_frame):\n",
    "    print(\"Transformed the raw data returned from extract()\")\n",
    "    return data_frame\n",
    "\n",
    "def load(data_frame, file_name):\n",
    "    # Write cleaned_data to a CSV using file_name\n",
    "    data_frame.to_csv(file_name)\n",
    "    print(f\"Successfully loaded data to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8a9a1-0d6c-4806-9080-b0315ef1c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(data_frame, file_name):\n",
    "  # Write cleaned_data to a CSV using file_name\n",
    "  data_frame.to_csv(file_name)\n",
    "  print(f\"Successfully loaded data to {file_name}\")\n",
    "\n",
    "extracted_data = extract(file_name=\"raw_data.csv\")\n",
    "\n",
    "# Transform extracted_data using transform() function\n",
    "transformed_data = transform(data_frame=extracted_data)\n",
    "\n",
    "# Load transformed_data to the file transformed_data.csv\n",
    "load(data_frame=transformed_data, file_name=\"transformed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5fe0cb-64ab-43e0-87a5-0ce1540ce10a",
   "metadata": {},
   "source": [
    "## The \"T\" in ELT\n",
    "\n",
    "Let's not forget about ELT! Here, the extract() and load() functions have been defined for you. Now, all that's left is to finish defining the transform() function and run the pipeline. Go get 'em!\n",
    "\n",
    "### Instructions\n",
    "    - Update the transform() function to call the .execute() method on the data_warehouse object.\n",
    "    - Use the newly-updated transform() function to populate data in the total_sales target table by transforming data in the raw_sales_data source table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4c7b413-53ed-4630-9449-1ce5c5aafd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(data_frame, table_name):\n",
    "    print(\"Loading extracted data to sale_items.\")\n",
    "\n",
    "def extract(file_name):\n",
    "    print(\"Extracted data from file storage.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da3b268-92ec-422f-95c4-ab28a0c15e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete building the transform() function\n",
    "def transform(source_table, target_table):\n",
    "  data_warehouse.execute(f\"\"\"\n",
    "  CREATE TABLE {target_table} AS\n",
    "      SELECT\n",
    "          CONCAT(\"Product ID: \", product_id),\n",
    "          quantity * price\n",
    "      FROM {source_table};\n",
    "  \"\"\")\n",
    "\n",
    "extracted_data = extract(file_name=\"raw_sales_data.csv\")\n",
    "load(data_frame=extracted_data, table_name=\"raw_sales_data\")\n",
    "\n",
    "# Populate total_sales by transforming raw_sales_data\n",
    "transform(source_table=\"raw_sales_data\", target_table=\"total_sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e42e78-d919-47e5-a6e9-629f55e73377",
   "metadata": {},
   "source": [
    "## Extracting, Transforming, and Loading Student Scores Data\n",
    "\n",
    "Alright, it's time to build your own ETL pipeline from scratch. In this exercise, you'll build three functions; extract(), transform(), and load(). Then, you'll use these functions to run your pipeline.\n",
    "\n",
    "The pandas library has been imported as pd. Enjoy!\n",
    "\n",
    "### Instructions 1/4\n",
    "    - In the extract() function, use the appropriate pandas function to read a CSV into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89fc60-7f45-4ac6-9988-2742aa03fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_name):\n",
    "    # Read a CSV with a path stored using file_name into memory\n",
    "    return pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc69176-0264-42d6-9671-74331df59356",
   "metadata": {},
   "source": [
    "### Instructions 2/4\n",
    "    - Update the transform() function to filter the data_frame to only include the columns industry_name and number_of_firms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a5ea30-7190-4607-b2db-ec997bf34c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_name):\n",
    "    return pd.read_csv(file_name)\n",
    "\n",
    "def transform(data_frame):\n",
    "    # Filter the data_frame to only incude a subset of columns\n",
    "    return data_frame.loc[:, [\"industry_name\", \"number_of_firms\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c9e0c-0056-40b1-9735-daf05fd74cfb",
   "metadata": {},
   "source": [
    "### Instructions 3/4\n",
    "    - In the load() function write the data_frame to a path stored using the parameter file_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b9f6de-b50b-438f-bc36-b32fdc0f616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_name):\n",
    "    return pd.read_csv(file_name)\n",
    "\n",
    "def transform(data_frame):\n",
    "    return data_frame.loc[:, [\"industry_name\", \"number_of_firms\"]]\n",
    "\n",
    "def load(data_frame, file_name):\n",
    "    # Write the data_frame to a CSV\n",
    "    data_frame.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37fa5f2-b16b-4384-8ece-5a54284e0352",
   "metadata": {},
   "source": [
    "### Instructions 4/4\n",
    "    - Pass the transformed_data DataFrame to the load() function, and run the ETL pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260874ce-7579-4918-98da-31098044a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_name):\n",
    "  return pd.read_csv(file_name)\n",
    "\n",
    "def transform(data_frame):\n",
    "  return data_frame.loc[:, [\"industry_name\", \"number_of_firms\"]]\n",
    "\n",
    "def load(data_frame, file_name):\n",
    "  data_frame.to_csv(file_name)\n",
    "  \n",
    "extracted_data = extract(file_name=\"raw_industry_data.csv\")\n",
    "transformed_data = transform(data_frame=extracted_data)\n",
    "\n",
    "# Pass the transformed_data DataFrame to the load() function\n",
    "load(data_frame=transformed_data, file_name=\"number_of_firms.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
