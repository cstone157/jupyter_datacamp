{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7791d8e-b3fc-4d8b-b33f-9f0c1118bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ee6df3-aeb5-40fa-bde5-05a96b9b7ab5",
   "metadata": {},
   "source": [
    "## Extracting data from parquet files\n",
    "\n",
    "One of the most common ways to ingest data from a source system is by reading data from a file, such as a CSV file. As data has gotten bigger, the need for better file formats has brought about new column-oriented file types, such as parquet files.\n",
    "\n",
    "In this exercise, you'll practice extracting data from a parquet file.\n",
    "\n",
    "### Instructions\n",
    "    - Read the parquet file at the path \"sales_data.parquet\" into a pandas DataFrame.\n",
    "    - Check the data types of the DataFrame via print()ing.\n",
    "    - Output the shape of the DataFrame, as well as it's head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae85d96e-9137-4088-bd7d-d630cb070470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the sales data into a DataFrame\n",
    "sales_data = pd.read_parquet(\"sales_data.parquet\", engine=\"fastparquet\")\n",
    "\n",
    "# Check the data type of the columns of the DataFrames\n",
    "print(sales_data.dtypes)\n",
    "\n",
    "# Print the shape of the DataFrame, as well as the head\n",
    "print(sales_data.shape)\n",
    "print(sales_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb9935-3241-427e-8390-68e6ba18046d",
   "metadata": {},
   "source": [
    "## Pulling data from SQL databases\n",
    "\n",
    "SQL databases are one of the most used data storage tools in the world. Many companies have teams of several individuals responsible for creating and maintaining these databases, which typically store data crucial for day-to-day operations. These SQL databases are commonly used as source systems for a wide range of data pipelines.\n",
    "\n",
    "For this exercise, pandas has been imported as pd. Best of luck!\n",
    "\n",
    "### Instructions\n",
    "    - Update the connection URI to create a connection engine for the sales database, using sqlalchemy.\n",
    "    - Query all rows and columns of the sales table and output the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d91d9-140c-42a6-8861-19d32c110d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "# Create a connection to the sales database\n",
    "db_engine = sqlalchemy.create_engine(\"postgresql+psycopg2://repl:password@localhost:5432/sales\")\n",
    "\n",
    "# Query the sales table\n",
    "raw_sales_data = pd.read_sql(\"SELECT * FROM sales\", db_engine)\n",
    "print(raw_sales_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
