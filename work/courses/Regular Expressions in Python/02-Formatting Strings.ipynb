{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa3d8fc2-c5d7-447f-9039-698aef034874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42f139ae-a76e-48c2-818f-43dd272d8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_article = 'In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5623b999-8589-4ccc-833a-ef1f7412a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the substrings to the variables\n",
    "first_pos = wikipedia_article[3:19].lower()\n",
    "second_pos = wikipedia_article[21:44].lower()\n",
    "my_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9ff92d6-9376-41e4-8546-0073be3b394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the substrings to the variables\n",
    "first_pos = wikipedia_article[3:19].lower()\n",
    "second_pos = wikipedia_article[21:44].lower()\n",
    "\n",
    "# Define string with placeholders \n",
    "my_list.append(\"The tool {} is used in {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74fc170a-786d-4159-8ac2-92d572392ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the substrings to the variables\n",
    "first_pos = wikipedia_article[3:19].lower()\n",
    "second_pos = wikipedia_article[21:44].lower()\n",
    "\n",
    "# Define string with placeholders \n",
    "my_list.append(\"The tool {} is used in {}\")\n",
    "\n",
    "# Define string with rearranged placeholders\n",
    "my_list.append(\"The tool {1} is used in {0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5af806c4-4f40-4239-b1e4-b66536ec17b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tool computer science is used in artificial intelligence\n",
      "The tool computer science is used in artificial intelligence\n",
      "The tool artificial intelligence is used in computer science\n",
      "The tool computer science is used in artificial intelligence\n",
      "The tool artificial intelligence is used in computer science\n"
     ]
    }
   ],
   "source": [
    "# Assign the substrings to the variables\n",
    "first_pos = wikipedia_article[3:19].lower()\n",
    "second_pos = wikipedia_article[21:44].lower()\n",
    "\n",
    "# Define string with placeholders \n",
    "my_list.append(\"The tool {} is used in {}\")\n",
    "\n",
    "# Define string with rearranged placeholders\n",
    "my_list.append(\"The tool {1} is used in {0}\")\n",
    "\n",
    "# Use format to print strings\n",
    "for my_string in my_list:\n",
    "  \tprint(my_string.format(first_pos, second_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "192529b1-60d1-40e1-a211-9c952e6985d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = ['artificial intelligence', 'neural networks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c280ff1-4bc7-4736-94d6-980623e2f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary\n",
    "plan = {\n",
    "  \t\t\"field\": courses[0],\n",
    "      \"tool\" : courses[1]\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "962c7930-d51b-48e2-a1d3-3c3f832340b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you are interested in artificial intelligence, you can take the course related to neural networks\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary\n",
    "plan = {\n",
    "        \"field\": courses[0],\n",
    "        \"tool\": courses[1]\n",
    "}\n",
    "\n",
    "# Complete the placeholders accessing elements of field and tool keys in the data dictionary\n",
    "my_message = \"If you are interested in {data[field]}, you can take the course related to {data[tool]}\"\n",
    "\n",
    "# Use the plan dictionary to replace placeholders\n",
    "print(my_message.format(data=plan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b92c7cbb-8861-49ab-b1e3-185bf1f8a2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning. Today is February 10, 2024. It's 21:18 ... time to work!\n"
     ]
    }
   ],
   "source": [
    "# Import datetime \n",
    "from datetime import datetime\n",
    "\n",
    "# Assign date to get_date\n",
    "get_date = datetime.now()\n",
    "\n",
    "# Add named placeholders with format specifiers\n",
    "message = \"Good morning. Today is {today:%B %d, %Y}. It's {today:%H:%M} ... time to work!\"\n",
    "\n",
    "# Use the format method replacing the placeholder with get_date\n",
    "print(message.format(today=get_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1db635e3-04c0-4a86-b7ec-f4795ac35053",
   "metadata": {},
   "outputs": [],
   "source": [
    "field1 = 'sexiest job'\n",
    "field2 = 'data is produced daily'\n",
    "field3 = 'Individuals'\n",
    "fact1 = 21\n",
    "fact2 = 2500000000000000000\n",
    "fact3 = 72.41415415151\n",
    "fact4 = 1.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0278906d-aab4-4255-bd7e-2be98c560982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is considered 'sexiest job' in the 21st century\n",
      "About 2.500000e+18 of data is produced daily in the world\n",
      "Individuals create around 72.41% of the data but only 1.1% is analyzed\n"
     ]
    }
   ],
   "source": [
    "# Complete the f-string\n",
    "print(f\"Data science is considered {field1!r} in the {fact1}st century\")\n",
    "\n",
    "# Complete the f-string\n",
    "print(f\"About {fact2:e} of {field2} in the world\")\n",
    "\n",
    "# Complete the f-string\n",
    "print(f\"{field3} create around {fact3:.2f}% of the data but only {fact4:.1f}% is analyzed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da1b6b37-e67c-447f-92e1-659e1e694502",
   "metadata": {},
   "outputs": [],
   "source": [
    "number1 = 120\n",
    "number2 = 7\n",
    "string1 = 'httpswww.datacamp.com'\n",
    "\n",
    "list_links = ['www.news.com',\n",
    " 'www.google.com',\n",
    " 'www.yahoo.com',\n",
    " 'www.bbc.com',\n",
    " 'www.msn.com',\n",
    " 'www.facebook.com',\n",
    " 'www.news.google.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d68c43aa-fb02-4289-94cf-088d1fd3e980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 tweets were downloaded in 7 minutes indicating a speed of 17.1 tweets per min\n",
      "www.datacamp.com\n",
      "Only 5.83% of the posts contain links\n"
     ]
    }
   ],
   "source": [
    "# Include both variables and the result of dividing them \n",
    "print(f\"{number1} tweets were downloaded in {number2} minutes indicating a speed of {number1/number2:.1f} tweets per min\")\n",
    "\n",
    "# Replace the substring https by an empty string\n",
    "print(f\"{string1.replace('https', '')}\")\n",
    "\n",
    "# Divide the length of list by 120 rounded to two decimals\n",
    "print(f\"Only {len(list_links)*100 / 120:.2f}% of the posts contain links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eeb9650f-d790-4d73-9383-fa4ea6719e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "east = {'date': datetime(2007, 4, 20, 0, 0), 'price': 1232443}\n",
    "west = {'date': datetime(2006, 5, 26, 0, 0), 'price': 1432673}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e8723be-b011-4be1-81b4-064137d1ad05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price for a house in the east neighborhood was $1232443 in 04-20-2007\n",
      "The price for a house in the west neighborhood was $1432673 in 05-26-2006.\n"
     ]
    }
   ],
   "source": [
    "# Access values of date and price in east dictionary\n",
    "print(f\"The price for a house in the east neighborhood was ${east['price']} in {east['date']:%m-%d-%Y}\")\n",
    "\n",
    "# Access values of date and price in west dictionary\n",
    "print(f\"The price for a house in the west neighborhood was ${west['price']} in {west['date']:%m-%d-%Y}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92041075-f669-4b52-8305-28f01b9b7d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool1 = 'Natural Language Toolkit'\n",
    "tool2 = 'TextBlob'\n",
    "tool3 = 'Gensim'\n",
    "description1 = 'suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.'\n",
    "description2 = 'Python library for processing textual data. It provides a simple API for diving into common natural language processing tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.'\n",
    "description3 = 'robust open-source vector space modeling and topic modeling toolkit implemented in Python. It uses NumPy, SciPy and optionally Cython for performance. Gensim is specifically designed to handle large text collections, using data streaming and efficient incremental algorithms, which differentiates it from most other scientific software packages that only target batch and in-memory processing.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08ca444e-1edb-4248-b71c-442afe0cd984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Template\n",
    "from string import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7904b242-a04f-46a4-b372-fa5b43cb302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Template\n",
    "from string import Template\n",
    "\n",
    "# Create a template\n",
    "wikipedia = Template(\"$tool is a $description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4960f741-5202-4bbb-844f-7c35373c3082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Toolkit is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\n",
      "TextBlob is a Python library for processing textual data. It provides a simple API for diving into common natural language processing tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
      "Gensim is a robust open-source vector space modeling and topic modeling toolkit implemented in Python. It uses NumPy, SciPy and optionally Cython for performance. Gensim is specifically designed to handle large text collections, using data streaming and efficient incremental algorithms, which differentiates it from most other scientific software packages that only target batch and in-memory processing.\n"
     ]
    }
   ],
   "source": [
    "# Import Template\n",
    "from string import Template\n",
    "\n",
    "# Create a template\n",
    "wikipedia = Template(\"$tool is a $description\")\n",
    "\n",
    "# Substitute variables in template\n",
    "print(wikipedia.substitute(tool=tool1, description=description1))\n",
    "print(wikipedia.substitute(tool=tool2, description=description2))\n",
    "print(wikipedia.substitute(tool=tool3, description=description3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b39f654-bf19-4ea8-978b-aab796f9f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = ['Natural Language Toolkit', '20', 'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4b8a765-a8ff-44db-b711-d982a90de963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are offering a 3-month beginner course on Natural Language Toolkit just for $ 20 monthly\n"
     ]
    }
   ],
   "source": [
    "# Import template\n",
    "from string import Template\n",
    "\n",
    "# Select variables\n",
    "our_tool = tools[0]\n",
    "our_fee = tools[1]\n",
    "our_pay = tools[2]\n",
    "\n",
    "# Create template\n",
    "course = Template(\"We are offering a 3-month beginner course on $tool just for $$ $fee ${pay}ly\")\n",
    "\n",
    "# Substitute identifiers with three variables\n",
    "print(course.substitute(tool=our_tool, fee=our_fee, pay=our_pay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af60958c-2df3-4502-917d-17b394c2b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {'answer1': 'I really like the app. But there are some features that can be improved'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc2cdd38-97af-4a5e-bb4d-648a0f396709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import template\n",
    "from string import Template\n",
    "\n",
    "# Complete template string using identifiers\n",
    "the_answers = Template(\"Check your answer 1: $answer1, and your answer 2: $answer2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41521a22-23bf-4310-932f-b4c5b7e0a747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing information\n"
     ]
    }
   ],
   "source": [
    "# Import template\n",
    "from string import Template\n",
    "\n",
    "# Complete template string using identifiers\n",
    "the_answers = Template(\"Check your answer 1: $answer1, and your answer 2: $answer2\")\n",
    "\n",
    "# Use substitute to replace identifiers\n",
    "try:\n",
    "    print(the_answers.substitute(answers))\n",
    "except KeyError:\n",
    "    print(\"Missing information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb3f2e-fedc-4292-be06-6478b11533b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import template\n",
    "from string import Template\n",
    "\n",
    "# Complete template string using identifiers\n",
    "the_answers = Template(\"Check your answer 1: $answer1, and your answer 2: $answer2\")\n",
    "\n",
    "# Use safe_substitute to replace identifiers\n",
    "try:\n",
    "    print(the_answers.safe_substitute(answers))\n",
    "except KeyError:\n",
    "    print(\"Missing information\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
