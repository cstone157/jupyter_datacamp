{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "042f0502-5209-4054-8cfd-0592e25171bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a0a7423-eac1-4bfb-911a-401fa36f123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = '@robot9! @robot4& I have a good feeling that the show isgoing to be amazing! @robot9$ @robot7%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f01e94-318e-43f3-8bfe-0a8c99ec9328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@robot9!', '@robot4&', '@robot9$', '@robot7%']\n"
     ]
    }
   ],
   "source": [
    "# Import the re module\n",
    "import re\n",
    "\n",
    "# Write the regex\n",
    "regex = r\"@robot\\d\\W\"\n",
    "\n",
    "# Find all matches of regex\n",
    "print(re.findall(regex, sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88ee568-3f27-4bdf-a9f0-be94c887b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = \"Unfortunately one of those moments wasn't a giant squid monster. User_mentions:2, likes: 9, number of retweets: 7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "768778fb-75c6-45df-8fbf-91e600bce7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User_mentions:2']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain user mentions\n",
    "print(re.findall(r\"User_mentions:\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aacd2c7-86fb-4fdb-8cac-a0a07f51dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['likes: 9']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain number of likes\n",
    "print(re.findall(r\"likes:\\s\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a78cbcea-9c8f-4355-a957-1f4ee394b640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number of retweets: 7']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain number of retweets\n",
    "print(re.findall(r\"number\\sof\\sretweets:\\s\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af2a7001-c8d7-48f7-ad91-d4f74c802f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = 'He#newHis%newTin love with$newPscrappy. #8break%He is&newYmissing him@newLalready'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "505533c7-8982-4fbc-90bd-f104aa53dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex to match pattern separating sentences\n",
    "regex_sentence = r\"\\W\\dbreak\\W\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0611022e-14bb-4620-8566-991ad70ea25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex to match pattern separating sentences\n",
    "regex_sentence = r\"\\W\\dbreak\\W\"\n",
    "\n",
    "# Replace the regex_sentence with a space\n",
    "sentiment_sub = re.sub(regex_sentence, \" \", sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2fdc3a2-9bcf-487b-b171-fffc08d9ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex to match pattern separating sentences\n",
    "regex_sentence = r\"\\W\\dbreak\\W\"\n",
    "\n",
    "# Replace the regex_sentence with a space\n",
    "sentiment_sub = re.sub(regex_sentence, \" \", sentiment_analysis)\n",
    "\n",
    "# Write a regex to match pattern separating words\n",
    "regex_words = r\"\\Wnew\\w\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe67879c-f038-48d2-a95f-7779869a90d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heisin love withscrappy.  He ismissing himalready\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match pattern separating sentences\n",
    "regex_sentence = r\"\\W\\dbreak\\W\"\n",
    "\n",
    "# Replace the regex_sentence with a space\n",
    "sentiment_sub = re.sub(regex_sentence, \" \", sentiment_analysis)\n",
    "\n",
    "# Write a regex to match pattern separating words\n",
    "regex_words = r\"\\Wnew\\w\"\n",
    "\n",
    "# Replace the regex_words and print the result\n",
    "sentiment_final = re.sub(regex_words, \"\", sentiment_sub)\n",
    "print(sentiment_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c405bb09-54a2-4364-b7ed-c295a24456ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = pd.Series(data={545: 'Boredd. Colddd @blueKnight39 Internet keeps stuffing up. Save me! https://www.tellyourstory.com',\n",
    "                         546: \"I had a horrible nightmare last night @anitaLopez98 @MyredHat31 which affected my sleep, now I'm really tired\",\n",
    "                         547: 'im lonely  keep me company @YourBestCompany! @foxRadio https://radio.foxnews.com 22 female, new york'}, index=[545, 546, 547])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04730e62-536c-4d75-a263-e55d8ec490cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.tellyourstory.com']\n",
      "['@blueKnight39']\n",
      "[]\n",
      "['@anitaLopez98', '@MyredHat31']\n",
      "['https://radio.foxnews.com']\n",
      "['@YourBestCompany!', '@foxRadio']\n"
     ]
    }
   ],
   "source": [
    "# Import re module\n",
    "import re\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Write regex to match http links and print out result\n",
    "    print(re.findall(r\"https:\\S+\", tweet))\n",
    "    \n",
    "    # Write regex to match user mentions and print out result\n",
    "    print(re.findall(r\"@\\S+\", tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89240b45-a5ce-4200-b589-fbe598d9f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = pd.Series(data={232: 'I would like to apologize for the repeated Video Games Live related tweets. 32 minutes ago',\n",
    "                         233: '@zaydia but i cant figure out how to get there / back / pay for a hotel 1st May 2019',\n",
    "                         234: 'FML: So much for seniority, bc of technological ineptness 23rd June 2018 17:54'}, index=[232, 233, 234])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37b27f15-6fd4-40f9-abae-7d5178041a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['32 minutes ago']\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates\n",
    "for date in sentiment_analysis:\n",
    "    print(re.findall(r\"\\d{1,2}\\s\\S+\\sago\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1bfda60-e7df-4b0c-acd2-21507e2f360f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['1st May 2019']\n",
      "['23rd June 2018']\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates\n",
    "for date in sentiment_analysis:\n",
    "    print(re.findall(r\"\\d{1,2}\\w{2}\\s\\S+\\s\\d{4}\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10635d01-4f95-42a0-890b-258c4d3076d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['23rd June 2018 17:54']\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates\n",
    "for date in sentiment_analysis:\n",
    "    print(re.findall(r\"\\d{1,2}\\w{1,2}\\s\\S+\\s\\d{4}\\s\\d{1,2}:\\d{2}\",date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a792951e-2fbd-44a4-a86a-312ede832bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = 'ITS NOT ENOUGH TO SAY THAT IMISS U #MissYou #SoMuch #Friendship #Forever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "342569f4-68a3-41c2-9095-6a71ac322517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex matching the hashtag pattern\n",
    "regex = r\"#\\w+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9c3b3d4-0ae4-461f-b0d6-e06f80885c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex matching the hashtag pattern\n",
    "regex = r\"#\\w+\"\n",
    "\n",
    "# Replace the regex by an empty string\n",
    "no_hashtag = re.sub(regex, \"\", sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a429421f-103b-4cd8-a4c9-bb8c125cb7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ITS', 'NOT', 'ENOUGH', 'TO', 'SAY', 'THAT', 'IMISS', 'U', '']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex matching the hashtag pattern\n",
    "regex = r\"#\\w+\"\n",
    "\n",
    "# Replace the regex by an empty string\n",
    "no_hashtag = re.sub(regex, \"\", sentiment_analysis)\n",
    "\n",
    "# Get tokens by splitting text\n",
    "print(re.split(r\"\\s+\", no_hashtag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15e4575a-31dd-4d02-bc40-ad6091ff5bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = pd.Series(data={780: 'AIshadowhunters.txt aaaaand back to my literature review. At least i have a friendly cup of coffee to keep me company',\n",
    "                         781: \"ouMYTAXES.txt I am worried that I won't get my $900 even though I paid tax last year\"}, index=[780, 781])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdced5ed-e82e-4496-8cc0-35950a7358dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AIshadowhunters.txt']\n",
      " aaaaand back to my literature review. At least i have a friendly cup of coffee to keep me company\n",
      "['ouMYTAXES.txt']\n",
      " I am worried that I won't get my $900 even though I paid tax last year\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match text file name\n",
    "regex = r\"^[aeiouAEIOU]{2,3}\\w+.txt\"\n",
    "\n",
    "for text in sentiment_analysis:\n",
    "    # Find all matches of the regex\n",
    "    print(re.findall(regex, text))\n",
    "    \n",
    "    # Replace all matches with empty string\n",
    "    print(re.sub(regex, \"\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de51e5ce-d49f-469a-835e-1ecfda66f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = ['n.john.smith@gmail.com', '87victory@hotmail.com', '!#mary-=@msca.net']\n",
    "passwords = ['Apple34!rose', 'My87hou#4$', 'abc123']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5076b13-ae4e-43e6-aef5-59c6b1931552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email n.john.smith@gmail.com is a valid email\n",
      "The email 87victory@hotmail.com is a valid email\n",
      "The email !#mary-=@msca.net is invalid\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match a valid email address\n",
    "regex = r\"^[a-zA-Z0-9!#%&*$.]+@\\w+\\.com\"\n",
    "\n",
    "for example in emails:\n",
    "    # Match the regex to the string\n",
    "    if re.match(regex, example):\n",
    "        # Complete the format method to print out the result\n",
    "        print(\"The email {email_example} is a valid email\".format(email_example=example))\n",
    "    else:\n",
    "        print(\"The email {email_example} is invalid\".format(email_example=example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4253779e-da40-4f19-a26a-fa8736f76a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The password Apple34!rose is a valid password\n",
      "The password My87hou#4$ is a valid password\n",
      "The password abc123 is invalid\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match a valid password\n",
    "regex = r\"[a-zA-Z0-9*#$%!&.]{8,20}\"\n",
    "\n",
    "for example in passwords:\n",
    "    # Scan the strings to find a match\n",
    "    if re.match(regex, example):\n",
    "        # Complete the format method to print out the result\n",
    "        print(\"The password {pass_example} is a valid password\".format(pass_example=example))\n",
    "    else:\n",
    "        print(\"The password {pass_example} is invalid\".format(pass_example=example))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5bfc1c1-24a4-490c-9413-2928a01d04f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'I want to see that <strong>amazing show</strong> again!'\n",
    "sentiment_analysis = 'Was intending to finish editing my 536-page novel manuscript tonight, but that will probably not happen. And only 12 pages are left '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "101547c5-d6fb-4911-a1e1-ff83876de9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to see that amazing show again!\n"
     ]
    }
   ],
   "source": [
    "# Import re\n",
    "import re\n",
    "\n",
    "# Write a regex to eliminate tags\n",
    "string_notags = re.sub(r\"<.+?>\", \"\", string)\n",
    "\n",
    "# Print out the result\n",
    "print(string_notags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb447a6e-a6fb-45cd-b42e-a3879bec16ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '3', '6', '1', '2']\n"
     ]
    }
   ],
   "source": [
    "# Write a lazy regex expression \n",
    "numbers_found_lazy = re.findall(r\"\\d+?\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(numbers_found_lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd41f9cf-6a22-4be7-a165-b13b58b04b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['536', '12']\n"
     ]
    }
   ],
   "source": [
    "# Write a greedy regex expression \n",
    "numbers_found_greedy = re.findall(r\"\\d+\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(numbers_found_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b139cda9-4748-44a7-b7cd-afefcfb73881",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = \"Put vacation photos online (They were so cute) a few yrs ago. PC crashed, and now I forget the name of the site (I'm crying). \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cd277d2-22ad-4c0b-9352-09b338720bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(They were so cute)', \"(I'm crying)\"]\n"
     ]
    }
   ],
   "source": [
    "# Write a greedy regex expression to match \n",
    "sentences_found_greedy = re.findall(r\"\\(.+?\\)\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(sentences_found_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa8b52a4-c826-4434-8270-0c472bb53c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(They were so cute)', \"(I'm crying)\"]\n"
     ]
    }
   ],
   "source": [
    "# Write a lazy regex expression\n",
    "sentences_found_lazy = re.findall(r\"\\(.+?\\)\", sentiment_analysis)\n",
    "\n",
    "# Print out the results\n",
    "print(sentences_found_lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5001d-94f9-4b23-9354-7902370109e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
