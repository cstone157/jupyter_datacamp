{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73fd4798-18c1-4ec3-b5c0-58be35652678",
   "metadata": {},
   "source": [
    "## Write a parameter file\n",
    "\n",
    "In this exercise, you will be given a DVC parameter file with some missing values. Your task is to fill in the blanks to complete the parameter file. This exercise will help you understand how DVC manages parameters and how they influence different stages of your project.\n",
    "\n",
    "The parameter file provided has two main sections: preprocess and train_and_evaluate. Each section contains various parameters related to data preprocessing and model training, respectively.\n",
    "\n",
    "### Ide Exercise Instruction\n",
    "    - Add Date as a column to drop in the preprocess section.\n",
    "    - Add RainTomorrow as target column in the preprocess section.\n",
    "    - Add 2 as number of estimators for for the Random Forest Classifier Model in train_and_evaluate section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f89263-6869-4137-b685-a4cb4d06a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params.yaml\n",
    "\n",
    "# preprocess:\n",
    "#   # Add Date as a column to drop\n",
    "#   drop_colnames:\n",
    "#     - Date\n",
    "#   # Add RainTomorrow as target column\n",
    "#   target_column: RainTomorrow\n",
    "#   categorical_features:\n",
    "#     - Location\n",
    "#     - WindGustDir\n",
    "#     - WindDir9am\n",
    "#     - WindDir3pm\n",
    "#     - RainToday\n",
    "# train_and_evaluate:\n",
    "#   target_column: RainTomorrow\n",
    "#   train_test_split:\n",
    "#     test_size: 0.2\n",
    "#     random_state: 1993\n",
    "#   shuffle: true\n",
    "#   shuffle_random_state: 1993\n",
    "#   # Add 2 as number of estimators for rfc classifier\n",
    "#   rfc_params:\n",
    "#     n_estimators: 2\n",
    "#     max_depth: 2\n",
    "#     random_state: 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d9e495-aedf-4d1f-acbf-17df0ab81fcc",
   "metadata": {},
   "source": [
    "## Designing a DVC pipeline\n",
    "\n",
    "Designing a DVC pipeline, or DAG, is fundamental to leveraging DVC in your machine learning workflows. DAGs allow us to codify inputs, outputs, and execution of a certain step. The outputs of one step can serve as input to one or more steps, thereby naturally setting the right dependencies between steps.\n",
    "\n",
    "In this exercise, you'll work on designing an ML workflow that contains four stages, namely,\n",
    "\n",
    "    - Data preprocessing (preprocess_stage)\n",
    "    - Data splitting (split_stage)\n",
    "    - Model training (train_stage)\n",
    "    - Model evaluation (evaluate_stage)\n",
    "\n",
    "We will exclusively work with the dvc stage add commands. Scroll down to the end of the shell script file (dvc_dag_stages_add.sh) if needed.\n",
    "\n",
    "### Ide Exercise Instruction\n",
    "    - Add processed_data.csv as output from preprocess_stage.\n",
    "    - Add parameters from the split section of the default parameter file to the split_stage.\n",
    "    - Add model.pkl as one of the dependencies in the evaluate_stage.\n",
    "    - Run the bash file by running bash dvc_dag_stages_add.sh command on the terminal. Notice how dvc.yaml gets populated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98112d4-89fa-4aa9-a29f-be8fddc21ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dvc_dag_stages_add.sh\n",
    "\n",
    "# #!/bin/bash\n",
    "\n",
    "# # Preprocess stage\n",
    "# # Output is processed_data.csv\n",
    "# dvc stage add --force \\\n",
    "# -n preprocess_stage \\\n",
    "# -o processed_data.csv \\\n",
    "# -d raw_data.csv \\\n",
    "# -d preprocess.py \\\n",
    "# -d processed_data.csv \\\n",
    "# python3 preprocess.py\n",
    "\n",
    "\n",
    "# # Split stage\n",
    "# # This stage uses parameters from `split` section of params.yaml\n",
    "# dvc stage add --force \\\n",
    "# -n split_stage \\\n",
    "# -p split \\\n",
    "# -d processed_data.csv \\\n",
    "# -d split.py \\\n",
    "# -o train_data.csv \\\n",
    "# -o eval_data.csv \\\n",
    "# python3 split.py\n",
    "\n",
    "\n",
    "# # Train stage\n",
    "# # This stage generates model.pkl as output\n",
    "# dvc stage add --force \\\n",
    "# -n train_stage \\\n",
    "# -p train \\\n",
    "# -d train_data.csv \\\n",
    "# -d train.py \\\n",
    "# -o model.pkl \\\n",
    "# python3 train.py\n",
    "\n",
    "\n",
    "# # Evaluate stage\n",
    "# # This stage uses model.pkl as one of the input\n",
    "# dvc stage add --force \\\n",
    "# -n evaluate_stage \\\n",
    "# -p evaluate \\\n",
    "# -d eval_data.csv \\\n",
    "# -d model.pkl \\\n",
    "# -d evaluate.py \\\n",
    "# -o metrics.json \\\n",
    "# python3 evaluate.py\n",
    "\n",
    "#$ bash dvc_dag_stages_add.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea110f3-f7d2-4409-93a3-4fb2c54d7831",
   "metadata": {},
   "source": [
    "## Visualizing a DVC pipeline\n",
    "\n",
    "In this exercise, you will learn to use the dvc dag command with different flags to gain various insights about your project's pipeline. Understanding these flags and their effects on the dvc dag command's output will help you better manage and understand your project's pipeline.\n",
    "\n",
    "Remember, the goal of this exercise is not just to execute the commands but to understand the nuances of the dvc dag command and how different flags alter its output.\n",
    "\n",
    "NOTE: You can use arrow keys to scroll the terminal outputs and use the q key to exit out.\n",
    "\n",
    "### Ide Exercise Instruction\n",
    "    - Run the dvc dag command without any flags and observe the output.\n",
    "    - Run the dvc dag command with the --outs flag and compare the output with the previous step.\n",
    "    - Run the dvc dag command with a train stage as a target and observe how the output changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a43bab0-d470-4bd4-b17f-bd25c4561393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#$ dvc dag\n",
    "#$ dvc dag --outs\n",
    "#$ dvc dag train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf8c35-30c8-4166-96d9-78e4db5ae1fe",
   "metadata": {},
   "source": [
    "## Execute a ML model training pipeline\n",
    "\n",
    "DVC pipelines are used to ensure reproducibility in your project.\n",
    "\n",
    "In this exercise, you will build on the learnings of creating a pipeline in the dvc.yaml file and execute the steps to train a machine-learning model using a structured approach. Your task is to execute different variants of dvc repro command to understand the nuances of it.\n",
    "\n",
    "### Ide Exercise Instruction\n",
    "    - Execute a dry run of the pipeline. Understand the steps and execution order.\n",
    "    - Execute only the preprocessing stage of the pipeline that is specified under preprocess block in dvc.yaml. Observe changes to the dvc.lock file.\n",
    "    - Execute only the training/evaluation stage of the pipeline that is specified under train_and_evaluate block in dvc.yaml. Observe changes to the dvc.lock file.\n",
    "    - Execute the entire DVC pipeline. Notice how the caching in DVC skips the actual execution of the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e0364-2163-4a7a-965a-5e73f24b2f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#$ dvc repro --dry\n",
    "#$ dvc repro preprocess\n",
    "#$ dvc repro train_and_evaluate\n",
    "#$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763c0c8-3e9e-4c12-821f-34fe55a53755",
   "metadata": {},
   "source": [
    "## Tracking DVC Metrics\n",
    "\n",
    "DVC pipelines are employed to guarantee the reproducibility of your project.\n",
    "\n",
    "In this exercise, you will expand on your knowledge of constructing a pipeline in the dvc.yaml file and carry out the steps to train a machine learning model in a systematic manner. Your assignment involves executing various forms of the dvc metrics command to comprehend its subtleties. We have already run the pipeline once and committed the metrics file to Git.\n",
    "\n",
    "### Ide Exercise Instruction\n",
    "    - Print the current metrics by running appropriate dvc metrics subcommand.\n",
    "    - Change n_estimators to 3 in line 20 of opened params.yaml file.\n",
    "    - Execute the DVC pipeline.\n",
    "    - Compare the changed metrics with the previous run using appropriate dvc metrics subcommand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8581ce-d75c-492a-8bd1-83b94daf9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#$ dvc metrics show\n",
    "#$ dvc repro\n",
    "#$ dvc metrics diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff632e6-c540-4e00-9241-4d6ea20a6edd",
   "metadata": {},
   "source": [
    "## Adding plots to dvc.yaml\n",
    "\n",
    "In this exercise, you are tasked to fill in the dvc.yaml file that outlines a model training process.\n",
    "\n",
    "The files preprocess_dataset.py and train_and_evaluate.py are responsible for data preprocessing and model training/evaluation respectively, using weather.csv from the raw_dataset folder as input. The output of the model training code is the predictions.csv file, which includes the predictions and the actual values from the test dataset, and a metrics.json file that holds structured metrics data. The predictions.csv file will be utilized to create a confusion matrix plot.\n",
    "\n",
    "### Ide Exercise Instruction\n",
    "    - Set the plot target to the output file containing predictions data.\n",
    "    - Set the plot template to confusion to plot the confusion matrix.\n",
    "    - Set the correct value for cache key to track plots in Git repository instead of DVC remote.\n",
    "    - Execute the pipeline and then run dvc plots show. This should generate a file dvc_plots/index.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6d0057-01e9-454b-b6b1-7fba9d2623b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stages:\n",
    "#   preprocess:\n",
    "#     cmd: python3 preprocess_dataset.py params.yaml raw_dataset/weather.csv processed_dataset/weather.csv\n",
    "#     deps:\n",
    "#     - preprocess_dataset.py\n",
    "#     - raw_dataset/weather.csv\n",
    "#     - utils_and_constants.py\n",
    "#     params:\n",
    "#     - preprocess\n",
    "#     outs:\n",
    "#     - processed_dataset/weather.csv\n",
    "#   train_and_evaluate:\n",
    "#     cmd: python3 train_and_evaluate.py params.yaml processed_dataset/weather.csv\n",
    "#     plots:\n",
    "#       # Set the target to the file containing predictions data\n",
    "#       - predictions.csv:\n",
    "#           # Write the plot template\n",
    "#           template: confusion\n",
    "#           x: predicted_label\n",
    "#           y: true_label\n",
    "#           x_label: 'Predicted label'\n",
    "#           y_label: 'True label'\n",
    "#           title: Confusion matrix\n",
    "#           # Set the cache parameter to store\n",
    "#           # plot data in Git repository\n",
    "#           cache: git\n",
    "#     deps:\n",
    "#     - metrics_and_plots.py\n",
    "#     - model.py\n",
    "#     - processed_dataset/weather.csv\n",
    "#     - train_and_evaluate.py\n",
    "#     - utils_and_constants.py\n",
    "#     params:\n",
    "#     - train_and_evaluate\n",
    "#     outs:\n",
    "#     - confusion_matrix.png\n",
    "#     metrics:\n",
    "#       - metrics.json:\n",
    "#           cache: false\n",
    "\n",
    "#$ dvc plots show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
