{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98e11286-27fe-4d34-9433-597b9c3ab1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "\n",
    "tic_tac_toe = pd.read_csv('./../../data/tic-tac-toe.csv')\n",
    "candy = pd.read_csv('./../../data/candy-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2b0561-a188-486b-a8bd-ed4316c212c1",
   "metadata": {},
   "source": [
    "## Two samples\n",
    "### After building several classification models based on thetic_tac_toe dataset, you realize that some models do not generalize as well as others. You have created training and testing splits just as you have been taught, so you are curious why your validation process is not working.\n",
    "\n",
    "### After trying a different training, test split, you noticed differing accuracies for your machine learning model. Before getting too frustrated with the varying results, you have decided to see what else could be going on.\n",
    "\n",
    "### Instructions 1/3\n",
    "-    Create samples sample1 and sample2 with 200 observations that could act as possible testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2822fc2-f481-4825-9842-373d48561ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two different samples of 200 observations \n",
    "sample1 = tic_tac_toe.sample(200, random_state=1111)\n",
    "sample2 = tic_tac_toe.sample(200, random_state=1171)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe9f97b-ab89-4a6f-a3e0-e71615cef45f",
   "metadata": {},
   "source": [
    "### Instructions 2/3\n",
    "-    Use the list comprehension statement to find out how many observations these samples have in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc500c98-3c91-4787-8cd1-f4dfeaacf1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# Create two different samples of 200 observations \n",
    "sample1 = tic_tac_toe.sample(200, random_state=1111)\n",
    "sample2 = tic_tac_toe.sample(200, random_state=1171)\n",
    "\n",
    "# Print the number of common observations \n",
    "print(len([index for index in sample1.index if index in sample2.index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4813ee25-a9d3-41b6-ac8f-753e0bc1e64c",
   "metadata": {},
   "source": [
    "### Instructions 3/3\n",
    "-    Use the Series.value_counts() method to print the values in both samples for column Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adca63f0-e4ac-4f91-a5f1-1114292ee53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Class\n",
      "positive    134\n",
      "negative     66\n",
      "Name: count, dtype: int64\n",
      "Class\n",
      "positive    123\n",
      "negative     77\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create two different samples of 200 observations \n",
    "sample1 = tic_tac_toe.sample(200, random_state=1111)\n",
    "sample2 = tic_tac_toe.sample(200, random_state=1171)\n",
    "\n",
    "# Print the number of common observations \n",
    "print(len([index for index in sample1.index if index in sample2.index]))\n",
    "\n",
    "# Print the number of observations in the Class column for both samples \n",
    "print(sample1['Class'].value_counts())\n",
    "print(sample2['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ba034-834f-4752-be97-86d6c29bc38e",
   "metadata": {},
   "source": [
    "## scikit-learn's KFold()\n",
    "### You just finished running a colleagues code that creates a random forest model and calculates an out-of-sample accuracy. You noticed that your colleague's code did not have a random state, and the errors you found were completely different than the errors your colleague reported.\n",
    "\n",
    "### To get a better estimate for how accurate this random forest model will be on new data, you have decided to generate some indices to use for KFold cross-validation.\n",
    "\n",
    "### Instructions\n",
    "-    Call the KFold() method to split data using five splits, shuffling, and a random state of 1111.\n",
    "-    Use the split() method of KFold on X.\n",
    "-    Print the number of indices in both the train and validation indices lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85c7ed37-8296-477e-ae06-2768b2d8de54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = candy[[\"chocolate\", \"fruity\", \"caramel\", \"peanutyalmondy\", \"nougat\", \"crispedricewafer\", \"hard\", \"bar\", \"pluribus\", \"sugarpercent\", \"pricepercent\"]].values\n",
    "y = candy[[\"winpercent\"]].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3088fa19-9aeb-4c1e-ac5a-171e2b410038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n",
      "Number of training indices: 68\n",
      "Number of validation indices: 17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Use KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1111)\n",
    "\n",
    "# Create splits\n",
    "splits = kf.split(X)\n",
    "\n",
    "# Print the number of indices\n",
    "for train_index, val_index in splits:\n",
    "    print(\"Number of training indices: %s\" % len(train_index))\n",
    "    print(\"Number of validation indices: %s\" % len(val_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319152a8-4d08-4a1f-a7ed-a59913ea7a6c",
   "metadata": {},
   "source": [
    "## Using KFold indices\n",
    "### You have already created splits, which contains indices for the candy-data dataset to complete 5-fold cross-validation. To get a better estimate for how well a colleague's random forest model will perform on a new data, you want to run this model on the five different training and validation indices you just created.\n",
    "\n",
    "### In this exercise, you will use these indices to check the accuracy of this model using the five different splits. A for loop has been provided to assist with this process.\n",
    "\n",
    "### Instructions\n",
    "-    Use train_index and val_index to call the correct indices of X and y when creating training and validation data.\n",
    "-    Fit rfc using the training dataset\n",
    "-    Use rfc to create predictions for validation dataset and print the validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aeb0ef6c-df7e-475d-b925-e4ef25b90d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1111)\n",
    "\n",
    "# Create splits\n",
    "splits = kf.split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7e2f9f5-81eb-4ddc-a9c3-68023c49b49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split accuracy: 150.99298148707666\n",
      "Split accuracy: 171.22206240542593\n",
      "Split accuracy: 131.72569156195593\n",
      "Split accuracy: 80.61940183841385\n",
      "Split accuracy: 221.63020627476214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
    "\n",
    "# Access the training and validation indices of splits\n",
    "for train_index, val_index in splits:\n",
    "    # Setup the training and validation data\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_val, y_val = X[val_index], y[val_index]\n",
    "    # Fit the random forest model\n",
    "    rfc.fit(X_train, y_train)\n",
    "    # Make predictions, and print the accuracy\n",
    "    predictions = rfc.predict(X_val)\n",
    "    print(\"Split accuracy: \" + str(mean_squared_error(y_val, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0b70a-20c9-4e52-bb0d-cf4ea2ccad4f",
   "metadata": {},
   "source": [
    "## scikit-learn's methods\n",
    "### You have decided to build a regression model to predict the number of new employees your company will successfully hire next month. You open up a new Python script to get started, but you quickly realize that sklearn has a lot of different modules. Let's make sure you understand the names of the modules, the methods, and which module contains which method.\n",
    "\n",
    "### Follow the instructions below to load in all of the necessary methods for completing cross-validation using sklearn. You will use modules:\n",
    "\n",
    "##### -  metrics\n",
    "##### -  model_selection\n",
    "##### -  ensemble\n",
    "### Instructions\n",
    "-    Load the method for calculating the scores of cross-validation.\n",
    "-    Load the random forest regression method.\n",
    "-    Load the mean square error metric.\n",
    "-    Load the method for creating a scorer to use with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2218e115-64b4-4207-9a76-5b85f88d1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruction 1: Load the cross-validation method\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Instruction 2: Load the random forest regression model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instruction 3: Load the mean squared error method\n",
    "# Instruction 4: Load the function for creating a scorer\n",
    "from sklearn.metrics import mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae40414-cacb-4e2c-a3ba-9f22ae245c82",
   "metadata": {},
   "source": [
    "## Implement cross_val_score()\n",
    "### Your company has created several new candies to sell, but they are not sure if they should release all five of them. To predict the popularity of these new candies, you have been asked to build a regression model using the candy dataset. Remember that the response value is a head-to-head win-percentage against other candies.\n",
    "\n",
    "### Before you begin trying different regression models, you have decided to run cross-validation on a simple random forest model to get a baseline error to compare with any future results.\n",
    "\n",
    "### Instructions\n",
    "-    Fill in cross_val_score().\n",
    "-    Use X_train for the training data, and y_train for the response.\n",
    "-    Use rfc as the model, 10-fold cross-validation, and mse for the scoring function.\n",
    "-    Print the mean of the cv results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41f01528-9f48-430b-b551-b3db0d73a4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.30323056938693\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "# Set up cross_val_score\n",
    "cv = cross_val_score(estimator=rfc,\n",
    "                     X=X_train,\n",
    "                     y=y_train,\n",
    "                     cv=10,\n",
    "                     scoring=mse)\n",
    "\n",
    "# Print the mean error\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745dbca1-4c7e-478e-8a0f-6653a630784d",
   "metadata": {},
   "source": [
    "## Leave-one-out-cross-validation\n",
    "### Let's assume your favorite candy is not in the candy dataset, and that you are interested in the popularity of this candy. Using 5-fold cross-validation will train on only 80% of the data at a time. The candy dataset only has 85 rows though, and leaving out 20% of the data could hinder our model. However, using leave-one-out-cross-validation allows us to make the most out of our limited dataset and will give you the best estimate for your favorite candy's popularity!\n",
    "\n",
    "### In this exercise, you will use cross_val_score() to perform LOOCV.\n",
    "\n",
    "### Instructions\n",
    "-    Create a scorer using mean_absolute_error for cross_val_score() to use.\n",
    "-    Fill out cross_val_score() so that the model rfr, the newly defined mae_scorer, and LOOCV are used.\n",
    "-    Print the mean and the standard deviation of scores using numpy (loaded as np)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fb08703-e08f-48cd-9086-1656359df464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the errors is: 9.52044832324183.\n",
      "The standard deviation of the errors is: 7.349020637882744.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "\n",
    "# Create scorer\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=15, random_state=1111)\n",
    "\n",
    "# Implement LOOCV\n",
    "scores = cross_val_score(rfr, X=X, y=y, cv=y.shape[0], scoring=mae_scorer)\n",
    "\n",
    "# Print the mean and standard deviation\n",
    "print(\"The mean of the errors is: %s.\" % np.mean(scores))\n",
    "print(\"The standard deviation of the errors is: %s.\" % np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54780e20-153b-4c15-917e-bfbb137e6521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
